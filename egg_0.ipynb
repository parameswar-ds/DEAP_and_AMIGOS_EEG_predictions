{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "egg_0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFz0qdiGkKRL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "bcf89d3d-a17e-41c0-9774-60a51a4a6809"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dwuLsGzka4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/deap_egg_tuning/deap_egg_tuning.zip\", 'r')\n",
        "zip_ref.extractall(\"/data\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QawyRs-kkDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXoAOmXMk2AZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1=pd.read_csv(\"/data/deap_egg_tuning/data.csv\")\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYGgUasDk5WD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b5bafd30-3b43-46bd-9a93-49c61c0e36e7"
      },
      "source": [
        "data1.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(609024, 70)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNLoCv_rk9sl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "504e2d98-152c-4b39-c5bd-54935b88efbf"
      },
      "source": [
        "label1=pd.read_csv(\"/data/deap_egg_tuning/label.csv\")\n",
        "label1.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(609024, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFPr6BpJlBuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=data1.values"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr2qRdbelElX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "e30c2041-0de6-4fb1-97ea-cbd72d57d1cb"
      },
      "source": [
        "label1.isnull().sum()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjMeAYWllH6g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_val=label1.loc[:,'0']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRnjOvr9lKf9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c4b609d0-fd07-423b-ede1-5a954d89367a"
      },
      "source": [
        "y_val.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(609024,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9mZzIoflMz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "accbe52c-565c-4b16-cb52-f540e3c77b60"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x)\n",
        "x = scaler.transform(x)\n",
        "from keras.utils import to_categorical\n",
        "y = to_categorical(y_val)\n",
        "y"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9zXZXoelP0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "x = np.reshape(x, (x.shape[0],1,x.shape[1]))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxQH4FK5lXVs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "92034208-db14-4501-94d4-db788dffff8d"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(609024, 1, 70)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDdAeDTxlaid",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "42fdfdf0-30e4-4e6f-ce5d-91a2004143a2"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(609024, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2AdCJlOld54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 4)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGrlORh-ljV1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "ee182f4a-ff61-40cd-a8e3-d10e9ba4a4a8"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(487219, 1, 70)\n",
            "(487219, 10)\n",
            "(121805, 1, 70)\n",
            "(121805, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukdgxb5Allsq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "outputId": "2fb21cf8-3fc8-434f-8f9e-78ad024f308e"
      },
      "source": [
        "\n",
        "import tensorflow\n",
        "# from tensorflow.keras import models\n",
        "# from tensorflow.keras import layers\n",
        "# from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import LSTM,BatchNormalization,Activation\n",
        "model = Sequential()\n",
        "model.add(LSTM(512, batch_input_shape = (None, None, x.shape[2]),return_sequences=True))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(256,activation=\"relu\",return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(LSTM(128,activation=\"relu\",return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(LSTM(64,activation=\"relu\",return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "model.add(LSTM(32,activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Dense(10))\n",
        "\n",
        "rmsprop =tensorflow.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08)\n",
        "model.compile(loss='mean_squared_error',\n",
        "                  optimizer=rmsprop,\n",
        "                  metrics=['accuracy'])\n",
        "#adam = keras.optimizers.Adam(lr=0.5, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, None, 512)         1193984   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, None, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 512)         0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, None, 256)         787456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, None, 256)         1024      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, None, 256)         0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, None, 128)         197120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, None, 128)         512       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, None, 64)          49408     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, None, 64)          256       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, None, 64)          0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 2,244,682\n",
            "Trainable params: 2,242,698\n",
            "Non-trainable params: 1,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6TU6joMlyEa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "44832a29-f87d-4085-cc6d-c61ec5a10247"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs = 900, batch_size=300,validation_data= (x_test, y_test))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.7799 - accuracy: 0.1208 - val_loss: 0.0987 - val_accuracy: 0.1655\n",
            "Epoch 2/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.1598 - accuracy: 0.1462 - val_loss: 0.0866 - val_accuracy: 0.1929\n",
            "Epoch 3/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0997 - accuracy: 0.1721 - val_loss: 0.0852 - val_accuracy: 0.2192\n",
            "Epoch 4/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0867 - accuracy: 0.2156 - val_loss: 0.0827 - val_accuracy: 0.2579\n",
            "Epoch 5/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0839 - accuracy: 0.2469 - val_loss: 0.0812 - val_accuracy: 0.2809\n",
            "Epoch 6/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0828 - accuracy: 0.2674 - val_loss: 0.0801 - val_accuracy: 0.3000\n",
            "Epoch 7/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0819 - accuracy: 0.2824 - val_loss: 0.0791 - val_accuracy: 0.3224\n",
            "Epoch 8/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0812 - accuracy: 0.2954 - val_loss: 0.0781 - val_accuracy: 0.3342\n",
            "Epoch 9/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0805 - accuracy: 0.3066 - val_loss: 0.0770 - val_accuracy: 0.3486\n",
            "Epoch 10/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0799 - accuracy: 0.3164 - val_loss: 0.0762 - val_accuracy: 0.3570\n",
            "Epoch 11/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0793 - accuracy: 0.3253 - val_loss: 0.0754 - val_accuracy: 0.3667\n",
            "Epoch 12/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0787 - accuracy: 0.3332 - val_loss: 0.0745 - val_accuracy: 0.3787\n",
            "Epoch 13/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0782 - accuracy: 0.3409 - val_loss: 0.0738 - val_accuracy: 0.3878\n",
            "Epoch 14/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0777 - accuracy: 0.3484 - val_loss: 0.0730 - val_accuracy: 0.4005\n",
            "Epoch 15/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0772 - accuracy: 0.3552 - val_loss: 0.0723 - val_accuracy: 0.4084\n",
            "Epoch 16/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0767 - accuracy: 0.3612 - val_loss: 0.0716 - val_accuracy: 0.4151\n",
            "Epoch 17/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0763 - accuracy: 0.3682 - val_loss: 0.0709 - val_accuracy: 0.4207\n",
            "Epoch 18/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0759 - accuracy: 0.3726 - val_loss: 0.0703 - val_accuracy: 0.4323\n",
            "Epoch 19/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0755 - accuracy: 0.3778 - val_loss: 0.0698 - val_accuracy: 0.4372\n",
            "Epoch 20/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0751 - accuracy: 0.3833 - val_loss: 0.0691 - val_accuracy: 0.4427\n",
            "Epoch 21/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0747 - accuracy: 0.3903 - val_loss: 0.0685 - val_accuracy: 0.4516\n",
            "Epoch 22/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0743 - accuracy: 0.3931 - val_loss: 0.0680 - val_accuracy: 0.4549\n",
            "Epoch 23/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0740 - accuracy: 0.3980 - val_loss: 0.0675 - val_accuracy: 0.4615\n",
            "Epoch 24/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0736 - accuracy: 0.4025 - val_loss: 0.0669 - val_accuracy: 0.4688\n",
            "Epoch 25/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0732 - accuracy: 0.4070 - val_loss: 0.0666 - val_accuracy: 0.4686\n",
            "Epoch 26/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0729 - accuracy: 0.4107 - val_loss: 0.0659 - val_accuracy: 0.4793\n",
            "Epoch 27/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0726 - accuracy: 0.4148 - val_loss: 0.0654 - val_accuracy: 0.4824\n",
            "Epoch 28/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0723 - accuracy: 0.4188 - val_loss: 0.0651 - val_accuracy: 0.4857\n",
            "Epoch 29/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0720 - accuracy: 0.4226 - val_loss: 0.0646 - val_accuracy: 0.4919\n",
            "Epoch 30/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0717 - accuracy: 0.4257 - val_loss: 0.0642 - val_accuracy: 0.4948\n",
            "Epoch 31/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0714 - accuracy: 0.4292 - val_loss: 0.0639 - val_accuracy: 0.4972\n",
            "Epoch 32/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0712 - accuracy: 0.4316 - val_loss: 0.0635 - val_accuracy: 0.5035\n",
            "Epoch 33/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0708 - accuracy: 0.4357 - val_loss: 0.0632 - val_accuracy: 0.5057\n",
            "Epoch 34/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0706 - accuracy: 0.4387 - val_loss: 0.0629 - val_accuracy: 0.5083\n",
            "Epoch 35/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0703 - accuracy: 0.4414 - val_loss: 0.0625 - val_accuracy: 0.5125\n",
            "Epoch 36/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0701 - accuracy: 0.4434 - val_loss: 0.0620 - val_accuracy: 0.5172\n",
            "Epoch 37/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0699 - accuracy: 0.4468 - val_loss: 0.0622 - val_accuracy: 0.5153\n",
            "Epoch 38/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0696 - accuracy: 0.4505 - val_loss: 0.0614 - val_accuracy: 0.5223\n",
            "Epoch 39/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0694 - accuracy: 0.4509 - val_loss: 0.0612 - val_accuracy: 0.5269\n",
            "Epoch 40/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0692 - accuracy: 0.4531 - val_loss: 0.0607 - val_accuracy: 0.5308\n",
            "Epoch 41/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0690 - accuracy: 0.4564 - val_loss: 0.0602 - val_accuracy: 0.5344\n",
            "Epoch 42/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0688 - accuracy: 0.4582 - val_loss: 0.0605 - val_accuracy: 0.5308\n",
            "Epoch 43/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0686 - accuracy: 0.4610 - val_loss: 0.0598 - val_accuracy: 0.5414\n",
            "Epoch 44/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0684 - accuracy: 0.4620 - val_loss: 0.0595 - val_accuracy: 0.5438\n",
            "Epoch 45/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0682 - accuracy: 0.4651 - val_loss: 0.0594 - val_accuracy: 0.5423\n",
            "Epoch 46/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0681 - accuracy: 0.4667 - val_loss: 0.0589 - val_accuracy: 0.5490\n",
            "Epoch 47/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0678 - accuracy: 0.4691 - val_loss: 0.0590 - val_accuracy: 0.5473\n",
            "Epoch 48/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0677 - accuracy: 0.4710 - val_loss: 0.0584 - val_accuracy: 0.5518\n",
            "Epoch 49/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0675 - accuracy: 0.4725 - val_loss: 0.0581 - val_accuracy: 0.5550\n",
            "Epoch 50/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0673 - accuracy: 0.4750 - val_loss: 0.0579 - val_accuracy: 0.5588\n",
            "Epoch 51/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0672 - accuracy: 0.4764 - val_loss: 0.0578 - val_accuracy: 0.5570\n",
            "Epoch 52/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0671 - accuracy: 0.4777 - val_loss: 0.0575 - val_accuracy: 0.5610\n",
            "Epoch 53/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0669 - accuracy: 0.4793 - val_loss: 0.0573 - val_accuracy: 0.5630\n",
            "Epoch 54/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0667 - accuracy: 0.4815 - val_loss: 0.0570 - val_accuracy: 0.5650\n",
            "Epoch 55/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0665 - accuracy: 0.4834 - val_loss: 0.0567 - val_accuracy: 0.5684\n",
            "Epoch 56/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0664 - accuracy: 0.4848 - val_loss: 0.0566 - val_accuracy: 0.5700\n",
            "Epoch 57/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0663 - accuracy: 0.4856 - val_loss: 0.0565 - val_accuracy: 0.5694\n",
            "Epoch 58/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0661 - accuracy: 0.4882 - val_loss: 0.0561 - val_accuracy: 0.5730\n",
            "Epoch 59/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0660 - accuracy: 0.4894 - val_loss: 0.0563 - val_accuracy: 0.5699\n",
            "Epoch 60/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0659 - accuracy: 0.4898 - val_loss: 0.0557 - val_accuracy: 0.5776\n",
            "Epoch 61/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0657 - accuracy: 0.4924 - val_loss: 0.0556 - val_accuracy: 0.5788\n",
            "Epoch 62/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0656 - accuracy: 0.4922 - val_loss: 0.0554 - val_accuracy: 0.5821\n",
            "Epoch 63/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0655 - accuracy: 0.4946 - val_loss: 0.0553 - val_accuracy: 0.5838\n",
            "Epoch 64/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0653 - accuracy: 0.4968 - val_loss: 0.0552 - val_accuracy: 0.5823\n",
            "Epoch 65/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0653 - accuracy: 0.4973 - val_loss: 0.0550 - val_accuracy: 0.5835\n",
            "Epoch 66/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0651 - accuracy: 0.4992 - val_loss: 0.0547 - val_accuracy: 0.5860\n",
            "Epoch 67/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0649 - accuracy: 0.4998 - val_loss: 0.0548 - val_accuracy: 0.5859\n",
            "Epoch 68/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0648 - accuracy: 0.5017 - val_loss: 0.0546 - val_accuracy: 0.5890\n",
            "Epoch 69/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0647 - accuracy: 0.5031 - val_loss: 0.0544 - val_accuracy: 0.5899\n",
            "Epoch 70/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0646 - accuracy: 0.5041 - val_loss: 0.0542 - val_accuracy: 0.5923\n",
            "Epoch 71/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0645 - accuracy: 0.5049 - val_loss: 0.0539 - val_accuracy: 0.5946\n",
            "Epoch 72/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0644 - accuracy: 0.5057 - val_loss: 0.0537 - val_accuracy: 0.5944\n",
            "Epoch 73/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0644 - accuracy: 0.5062 - val_loss: 0.0535 - val_accuracy: 0.5986\n",
            "Epoch 74/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0642 - accuracy: 0.5084 - val_loss: 0.0534 - val_accuracy: 0.5994\n",
            "Epoch 75/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0641 - accuracy: 0.5097 - val_loss: 0.0531 - val_accuracy: 0.6020\n",
            "Epoch 76/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0640 - accuracy: 0.5100 - val_loss: 0.0534 - val_accuracy: 0.5978\n",
            "Epoch 77/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0639 - accuracy: 0.5116 - val_loss: 0.0530 - val_accuracy: 0.6021\n",
            "Epoch 78/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0638 - accuracy: 0.5117 - val_loss: 0.0527 - val_accuracy: 0.6046\n",
            "Epoch 79/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0637 - accuracy: 0.5132 - val_loss: 0.0528 - val_accuracy: 0.6026\n",
            "Epoch 80/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0636 - accuracy: 0.5140 - val_loss: 0.0526 - val_accuracy: 0.6072\n",
            "Epoch 81/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0635 - accuracy: 0.5154 - val_loss: 0.0530 - val_accuracy: 0.6039\n",
            "Epoch 82/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0634 - accuracy: 0.5162 - val_loss: 0.0524 - val_accuracy: 0.6112\n",
            "Epoch 83/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0634 - accuracy: 0.5165 - val_loss: 0.0519 - val_accuracy: 0.6144\n",
            "Epoch 84/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0632 - accuracy: 0.5183 - val_loss: 0.0519 - val_accuracy: 0.6123\n",
            "Epoch 85/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0631 - accuracy: 0.5194 - val_loss: 0.0518 - val_accuracy: 0.6135\n",
            "Epoch 86/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0631 - accuracy: 0.5207 - val_loss: 0.0516 - val_accuracy: 0.6161\n",
            "Epoch 87/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0630 - accuracy: 0.5212 - val_loss: 0.0516 - val_accuracy: 0.6166\n",
            "Epoch 88/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0629 - accuracy: 0.5225 - val_loss: 0.0517 - val_accuracy: 0.6141\n",
            "Epoch 89/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0628 - accuracy: 0.5227 - val_loss: 0.0514 - val_accuracy: 0.6175\n",
            "Epoch 90/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0628 - accuracy: 0.5225 - val_loss: 0.0514 - val_accuracy: 0.6180\n",
            "Epoch 91/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0627 - accuracy: 0.5250 - val_loss: 0.0511 - val_accuracy: 0.6235\n",
            "Epoch 92/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0626 - accuracy: 0.5249 - val_loss: 0.0511 - val_accuracy: 0.6197\n",
            "Epoch 93/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0625 - accuracy: 0.5262 - val_loss: 0.0508 - val_accuracy: 0.6219\n",
            "Epoch 94/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0624 - accuracy: 0.5269 - val_loss: 0.0510 - val_accuracy: 0.6192\n",
            "Epoch 95/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0623 - accuracy: 0.5281 - val_loss: 0.0505 - val_accuracy: 0.6262\n",
            "Epoch 96/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0622 - accuracy: 0.5293 - val_loss: 0.0504 - val_accuracy: 0.6256\n",
            "Epoch 97/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0622 - accuracy: 0.5290 - val_loss: 0.0507 - val_accuracy: 0.6233\n",
            "Epoch 98/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0620 - accuracy: 0.5312 - val_loss: 0.0504 - val_accuracy: 0.6278\n",
            "Epoch 99/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0620 - accuracy: 0.5310 - val_loss: 0.0503 - val_accuracy: 0.6293\n",
            "Epoch 100/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0620 - accuracy: 0.5318 - val_loss: 0.0500 - val_accuracy: 0.6285\n",
            "Epoch 101/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0619 - accuracy: 0.5326 - val_loss: 0.0499 - val_accuracy: 0.6287\n",
            "Epoch 102/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0618 - accuracy: 0.5329 - val_loss: 0.0498 - val_accuracy: 0.6302\n",
            "Epoch 103/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0618 - accuracy: 0.5332 - val_loss: 0.0499 - val_accuracy: 0.6314\n",
            "Epoch 104/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0616 - accuracy: 0.5346 - val_loss: 0.0496 - val_accuracy: 0.6340\n",
            "Epoch 105/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0617 - accuracy: 0.5347 - val_loss: 0.0496 - val_accuracy: 0.6348\n",
            "Epoch 106/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0615 - accuracy: 0.5364 - val_loss: 0.0495 - val_accuracy: 0.6334\n",
            "Epoch 107/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0614 - accuracy: 0.5376 - val_loss: 0.0494 - val_accuracy: 0.6361\n",
            "Epoch 108/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0614 - accuracy: 0.5376 - val_loss: 0.0492 - val_accuracy: 0.6369\n",
            "Epoch 109/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0613 - accuracy: 0.5376 - val_loss: 0.0492 - val_accuracy: 0.6370\n",
            "Epoch 110/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0613 - accuracy: 0.5388 - val_loss: 0.0491 - val_accuracy: 0.6357\n",
            "Epoch 111/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0612 - accuracy: 0.5396 - val_loss: 0.0491 - val_accuracy: 0.6382\n",
            "Epoch 112/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0612 - accuracy: 0.5404 - val_loss: 0.0490 - val_accuracy: 0.6385\n",
            "Epoch 113/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0610 - accuracy: 0.5409 - val_loss: 0.0486 - val_accuracy: 0.6418\n",
            "Epoch 114/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0610 - accuracy: 0.5412 - val_loss: 0.0492 - val_accuracy: 0.6350\n",
            "Epoch 115/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0609 - accuracy: 0.5425 - val_loss: 0.0487 - val_accuracy: 0.6413\n",
            "Epoch 116/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0609 - accuracy: 0.5426 - val_loss: 0.0491 - val_accuracy: 0.6361\n",
            "Epoch 117/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0608 - accuracy: 0.5429 - val_loss: 0.0482 - val_accuracy: 0.6451\n",
            "Epoch 118/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0607 - accuracy: 0.5435 - val_loss: 0.0484 - val_accuracy: 0.6422\n",
            "Epoch 119/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0607 - accuracy: 0.5445 - val_loss: 0.0483 - val_accuracy: 0.6436\n",
            "Epoch 120/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0606 - accuracy: 0.5453 - val_loss: 0.0484 - val_accuracy: 0.6441\n",
            "Epoch 121/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0606 - accuracy: 0.5459 - val_loss: 0.0479 - val_accuracy: 0.6479\n",
            "Epoch 122/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0606 - accuracy: 0.5460 - val_loss: 0.0484 - val_accuracy: 0.6438\n",
            "Epoch 123/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0604 - accuracy: 0.5469 - val_loss: 0.0481 - val_accuracy: 0.6467\n",
            "Epoch 124/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0604 - accuracy: 0.5473 - val_loss: 0.0478 - val_accuracy: 0.6491\n",
            "Epoch 125/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0603 - accuracy: 0.5482 - val_loss: 0.0476 - val_accuracy: 0.6488\n",
            "Epoch 126/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0603 - accuracy: 0.5482 - val_loss: 0.0475 - val_accuracy: 0.6520\n",
            "Epoch 127/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0603 - accuracy: 0.5492 - val_loss: 0.0474 - val_accuracy: 0.6516\n",
            "Epoch 128/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0601 - accuracy: 0.5502 - val_loss: 0.0476 - val_accuracy: 0.6503\n",
            "Epoch 129/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0601 - accuracy: 0.5505 - val_loss: 0.0477 - val_accuracy: 0.6479\n",
            "Epoch 130/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0601 - accuracy: 0.5510 - val_loss: 0.0477 - val_accuracy: 0.6496\n",
            "Epoch 131/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0600 - accuracy: 0.5514 - val_loss: 0.0471 - val_accuracy: 0.6555\n",
            "Epoch 132/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0600 - accuracy: 0.5523 - val_loss: 0.0472 - val_accuracy: 0.6533\n",
            "Epoch 133/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0599 - accuracy: 0.5523 - val_loss: 0.0469 - val_accuracy: 0.6564\n",
            "Epoch 134/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0598 - accuracy: 0.5534 - val_loss: 0.0470 - val_accuracy: 0.6556\n",
            "Epoch 135/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0599 - accuracy: 0.5524 - val_loss: 0.0467 - val_accuracy: 0.6578\n",
            "Epoch 136/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0598 - accuracy: 0.5541 - val_loss: 0.0467 - val_accuracy: 0.6578\n",
            "Epoch 137/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0597 - accuracy: 0.5547 - val_loss: 0.0469 - val_accuracy: 0.6579\n",
            "Epoch 138/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0596 - accuracy: 0.5555 - val_loss: 0.0466 - val_accuracy: 0.6590\n",
            "Epoch 139/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0596 - accuracy: 0.5553 - val_loss: 0.0466 - val_accuracy: 0.6580\n",
            "Epoch 140/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0596 - accuracy: 0.5561 - val_loss: 0.0466 - val_accuracy: 0.6596\n",
            "Epoch 141/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0595 - accuracy: 0.5573 - val_loss: 0.0464 - val_accuracy: 0.6601\n",
            "Epoch 142/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0595 - accuracy: 0.5570 - val_loss: 0.0466 - val_accuracy: 0.6576\n",
            "Epoch 143/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0593 - accuracy: 0.5582 - val_loss: 0.0463 - val_accuracy: 0.6601\n",
            "Epoch 144/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0594 - accuracy: 0.5579 - val_loss: 0.0461 - val_accuracy: 0.6620\n",
            "Epoch 145/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0592 - accuracy: 0.5598 - val_loss: 0.0462 - val_accuracy: 0.6631\n",
            "Epoch 146/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0593 - accuracy: 0.5592 - val_loss: 0.0460 - val_accuracy: 0.6624\n",
            "Epoch 147/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0593 - accuracy: 0.5587 - val_loss: 0.0459 - val_accuracy: 0.6641\n",
            "Epoch 148/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0591 - accuracy: 0.5602 - val_loss: 0.0465 - val_accuracy: 0.6577\n",
            "Epoch 149/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0592 - accuracy: 0.5595 - val_loss: 0.0462 - val_accuracy: 0.6614\n",
            "Epoch 150/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0591 - accuracy: 0.5603 - val_loss: 0.0458 - val_accuracy: 0.6640\n",
            "Epoch 151/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0591 - accuracy: 0.5605 - val_loss: 0.0457 - val_accuracy: 0.6666\n",
            "Epoch 152/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0590 - accuracy: 0.5617 - val_loss: 0.0459 - val_accuracy: 0.6651\n",
            "Epoch 153/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0589 - accuracy: 0.5621 - val_loss: 0.0456 - val_accuracy: 0.6669\n",
            "Epoch 154/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0590 - accuracy: 0.5622 - val_loss: 0.0454 - val_accuracy: 0.6703\n",
            "Epoch 155/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0589 - accuracy: 0.5633 - val_loss: 0.0455 - val_accuracy: 0.6692\n",
            "Epoch 156/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0588 - accuracy: 0.5629 - val_loss: 0.0455 - val_accuracy: 0.6676\n",
            "Epoch 157/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0588 - accuracy: 0.5636 - val_loss: 0.0453 - val_accuracy: 0.6690\n",
            "Epoch 158/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0587 - accuracy: 0.5639 - val_loss: 0.0452 - val_accuracy: 0.6718\n",
            "Epoch 159/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0586 - accuracy: 0.5657 - val_loss: 0.0452 - val_accuracy: 0.6692\n",
            "Epoch 160/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0586 - accuracy: 0.5658 - val_loss: 0.0452 - val_accuracy: 0.6710\n",
            "Epoch 161/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0585 - accuracy: 0.5673 - val_loss: 0.0452 - val_accuracy: 0.6699\n",
            "Epoch 162/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0585 - accuracy: 0.5670 - val_loss: 0.0450 - val_accuracy: 0.6711\n",
            "Epoch 163/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0584 - accuracy: 0.5669 - val_loss: 0.0451 - val_accuracy: 0.6710\n",
            "Epoch 164/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0585 - accuracy: 0.5674 - val_loss: 0.0449 - val_accuracy: 0.6750\n",
            "Epoch 165/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0584 - accuracy: 0.5678 - val_loss: 0.0449 - val_accuracy: 0.6734\n",
            "Epoch 166/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0584 - accuracy: 0.5675 - val_loss: 0.0451 - val_accuracy: 0.6713\n",
            "Epoch 167/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0583 - accuracy: 0.5681 - val_loss: 0.0448 - val_accuracy: 0.6746\n",
            "Epoch 168/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0583 - accuracy: 0.5690 - val_loss: 0.0449 - val_accuracy: 0.6723\n",
            "Epoch 169/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0583 - accuracy: 0.5694 - val_loss: 0.0445 - val_accuracy: 0.6777\n",
            "Epoch 170/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0582 - accuracy: 0.5697 - val_loss: 0.0444 - val_accuracy: 0.6786\n",
            "Epoch 171/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0581 - accuracy: 0.5703 - val_loss: 0.0447 - val_accuracy: 0.6753\n",
            "Epoch 172/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0581 - accuracy: 0.5710 - val_loss: 0.0444 - val_accuracy: 0.6769\n",
            "Epoch 173/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0581 - accuracy: 0.5704 - val_loss: 0.0444 - val_accuracy: 0.6777\n",
            "Epoch 174/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0581 - accuracy: 0.5709 - val_loss: 0.0442 - val_accuracy: 0.6808\n",
            "Epoch 175/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0579 - accuracy: 0.5728 - val_loss: 0.0441 - val_accuracy: 0.6796\n",
            "Epoch 176/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0579 - accuracy: 0.5720 - val_loss: 0.0441 - val_accuracy: 0.6798\n",
            "Epoch 177/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0579 - accuracy: 0.5719 - val_loss: 0.0441 - val_accuracy: 0.6791\n",
            "Epoch 178/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0578 - accuracy: 0.5729 - val_loss: 0.0445 - val_accuracy: 0.6751\n",
            "Epoch 179/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0578 - accuracy: 0.5735 - val_loss: 0.0438 - val_accuracy: 0.6825\n",
            "Epoch 180/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0578 - accuracy: 0.5731 - val_loss: 0.0436 - val_accuracy: 0.6851\n",
            "Epoch 181/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0578 - accuracy: 0.5738 - val_loss: 0.0440 - val_accuracy: 0.6818\n",
            "Epoch 182/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0577 - accuracy: 0.5742 - val_loss: 0.0439 - val_accuracy: 0.6810\n",
            "Epoch 183/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0577 - accuracy: 0.5738 - val_loss: 0.0438 - val_accuracy: 0.6838\n",
            "Epoch 184/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0577 - accuracy: 0.5745 - val_loss: 0.0437 - val_accuracy: 0.6839\n",
            "Epoch 185/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0576 - accuracy: 0.5756 - val_loss: 0.0437 - val_accuracy: 0.6834\n",
            "Epoch 186/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0576 - accuracy: 0.5760 - val_loss: 0.0435 - val_accuracy: 0.6856\n",
            "Epoch 187/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0576 - accuracy: 0.5764 - val_loss: 0.0436 - val_accuracy: 0.6843\n",
            "Epoch 188/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0575 - accuracy: 0.5762 - val_loss: 0.0436 - val_accuracy: 0.6839\n",
            "Epoch 189/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0574 - accuracy: 0.5766 - val_loss: 0.0434 - val_accuracy: 0.6868\n",
            "Epoch 190/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0575 - accuracy: 0.5770 - val_loss: 0.0435 - val_accuracy: 0.6839\n",
            "Epoch 191/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0574 - accuracy: 0.5768 - val_loss: 0.0432 - val_accuracy: 0.6882\n",
            "Epoch 192/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0574 - accuracy: 0.5776 - val_loss: 0.0431 - val_accuracy: 0.6885\n",
            "Epoch 193/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0574 - accuracy: 0.5775 - val_loss: 0.0431 - val_accuracy: 0.6890\n",
            "Epoch 194/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0574 - accuracy: 0.5778 - val_loss: 0.0432 - val_accuracy: 0.6882\n",
            "Epoch 195/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0573 - accuracy: 0.5793 - val_loss: 0.0432 - val_accuracy: 0.6875\n",
            "Epoch 196/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0573 - accuracy: 0.5786 - val_loss: 0.0432 - val_accuracy: 0.6876\n",
            "Epoch 197/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0572 - accuracy: 0.5795 - val_loss: 0.0432 - val_accuracy: 0.6875\n",
            "Epoch 198/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0572 - accuracy: 0.5803 - val_loss: 0.0428 - val_accuracy: 0.6910\n",
            "Epoch 199/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0571 - accuracy: 0.5803 - val_loss: 0.0431 - val_accuracy: 0.6884\n",
            "Epoch 200/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0571 - accuracy: 0.5806 - val_loss: 0.0426 - val_accuracy: 0.6937\n",
            "Epoch 201/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0571 - accuracy: 0.5803 - val_loss: 0.0429 - val_accuracy: 0.6893\n",
            "Epoch 202/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0570 - accuracy: 0.5817 - val_loss: 0.0428 - val_accuracy: 0.6920\n",
            "Epoch 203/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0570 - accuracy: 0.5811 - val_loss: 0.0427 - val_accuracy: 0.6910\n",
            "Epoch 204/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0570 - accuracy: 0.5819 - val_loss: 0.0430 - val_accuracy: 0.6895\n",
            "Epoch 205/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0568 - accuracy: 0.5830 - val_loss: 0.0427 - val_accuracy: 0.6919\n",
            "Epoch 206/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0569 - accuracy: 0.5824 - val_loss: 0.0427 - val_accuracy: 0.6910\n",
            "Epoch 207/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0569 - accuracy: 0.5823 - val_loss: 0.0427 - val_accuracy: 0.6906\n",
            "Epoch 208/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0569 - accuracy: 0.5835 - val_loss: 0.0426 - val_accuracy: 0.6928\n",
            "Epoch 209/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0568 - accuracy: 0.5839 - val_loss: 0.0426 - val_accuracy: 0.6919\n",
            "Epoch 210/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0567 - accuracy: 0.5840 - val_loss: 0.0426 - val_accuracy: 0.6929\n",
            "Epoch 211/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0568 - accuracy: 0.5840 - val_loss: 0.0423 - val_accuracy: 0.6952\n",
            "Epoch 212/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0566 - accuracy: 0.5850 - val_loss: 0.0421 - val_accuracy: 0.6979\n",
            "Epoch 213/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0567 - accuracy: 0.5846 - val_loss: 0.0426 - val_accuracy: 0.6941\n",
            "Epoch 214/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0567 - accuracy: 0.5843 - val_loss: 0.0422 - val_accuracy: 0.6965\n",
            "Epoch 215/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0567 - accuracy: 0.5835 - val_loss: 0.0425 - val_accuracy: 0.6937\n",
            "Epoch 216/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0566 - accuracy: 0.5847 - val_loss: 0.0422 - val_accuracy: 0.6958\n",
            "Epoch 217/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0566 - accuracy: 0.5854 - val_loss: 0.0420 - val_accuracy: 0.6987\n",
            "Epoch 218/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0566 - accuracy: 0.5855 - val_loss: 0.0422 - val_accuracy: 0.6966\n",
            "Epoch 219/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0565 - accuracy: 0.5871 - val_loss: 0.0419 - val_accuracy: 0.6984\n",
            "Epoch 220/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0564 - accuracy: 0.5873 - val_loss: 0.0420 - val_accuracy: 0.6976\n",
            "Epoch 221/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0564 - accuracy: 0.5868 - val_loss: 0.0418 - val_accuracy: 0.7001\n",
            "Epoch 222/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0564 - accuracy: 0.5873 - val_loss: 0.0418 - val_accuracy: 0.6998\n",
            "Epoch 223/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0563 - accuracy: 0.5883 - val_loss: 0.0421 - val_accuracy: 0.6961\n",
            "Epoch 224/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0564 - accuracy: 0.5875 - val_loss: 0.0417 - val_accuracy: 0.7009\n",
            "Epoch 225/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0563 - accuracy: 0.5884 - val_loss: 0.0420 - val_accuracy: 0.6976\n",
            "Epoch 226/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0563 - accuracy: 0.5883 - val_loss: 0.0419 - val_accuracy: 0.6991\n",
            "Epoch 227/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0563 - accuracy: 0.5884 - val_loss: 0.0416 - val_accuracy: 0.7012\n",
            "Epoch 228/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0562 - accuracy: 0.5889 - val_loss: 0.0415 - val_accuracy: 0.7026\n",
            "Epoch 229/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0563 - accuracy: 0.5888 - val_loss: 0.0417 - val_accuracy: 0.7007\n",
            "Epoch 230/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0562 - accuracy: 0.5894 - val_loss: 0.0417 - val_accuracy: 0.7010\n",
            "Epoch 231/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0561 - accuracy: 0.5900 - val_loss: 0.0414 - val_accuracy: 0.7018\n",
            "Epoch 232/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0561 - accuracy: 0.5890 - val_loss: 0.0413 - val_accuracy: 0.7027\n",
            "Epoch 233/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0561 - accuracy: 0.5902 - val_loss: 0.0416 - val_accuracy: 0.7007\n",
            "Epoch 234/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0561 - accuracy: 0.5907 - val_loss: 0.0416 - val_accuracy: 0.7012\n",
            "Epoch 235/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0560 - accuracy: 0.5916 - val_loss: 0.0413 - val_accuracy: 0.7037\n",
            "Epoch 236/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0560 - accuracy: 0.5916 - val_loss: 0.0413 - val_accuracy: 0.7039\n",
            "Epoch 237/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0560 - accuracy: 0.5915 - val_loss: 0.0411 - val_accuracy: 0.7047\n",
            "Epoch 238/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0560 - accuracy: 0.5914 - val_loss: 0.0413 - val_accuracy: 0.7041\n",
            "Epoch 239/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0559 - accuracy: 0.5919 - val_loss: 0.0414 - val_accuracy: 0.7035\n",
            "Epoch 240/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0559 - accuracy: 0.5920 - val_loss: 0.0413 - val_accuracy: 0.7036\n",
            "Epoch 241/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0559 - accuracy: 0.5923 - val_loss: 0.0412 - val_accuracy: 0.7046\n",
            "Epoch 242/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0559 - accuracy: 0.5923 - val_loss: 0.0409 - val_accuracy: 0.7083\n",
            "Epoch 243/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0558 - accuracy: 0.5931 - val_loss: 0.0411 - val_accuracy: 0.7044\n",
            "Epoch 244/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0558 - accuracy: 0.5936 - val_loss: 0.0409 - val_accuracy: 0.7060\n",
            "Epoch 245/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0558 - accuracy: 0.5936 - val_loss: 0.0412 - val_accuracy: 0.7055\n",
            "Epoch 246/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0558 - accuracy: 0.5932 - val_loss: 0.0409 - val_accuracy: 0.7075\n",
            "Epoch 247/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0558 - accuracy: 0.5930 - val_loss: 0.0411 - val_accuracy: 0.7067\n",
            "Epoch 248/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0558 - accuracy: 0.5936 - val_loss: 0.0408 - val_accuracy: 0.7079\n",
            "Epoch 249/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0558 - accuracy: 0.5938 - val_loss: 0.0409 - val_accuracy: 0.7078\n",
            "Epoch 250/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0557 - accuracy: 0.5946 - val_loss: 0.0408 - val_accuracy: 0.7070\n",
            "Epoch 251/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0556 - accuracy: 0.5950 - val_loss: 0.0407 - val_accuracy: 0.7088\n",
            "Epoch 252/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0556 - accuracy: 0.5954 - val_loss: 0.0405 - val_accuracy: 0.7097\n",
            "Epoch 253/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0556 - accuracy: 0.5950 - val_loss: 0.0410 - val_accuracy: 0.7065\n",
            "Epoch 254/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0556 - accuracy: 0.5959 - val_loss: 0.0405 - val_accuracy: 0.7100\n",
            "Epoch 255/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0554 - accuracy: 0.5970 - val_loss: 0.0406 - val_accuracy: 0.7094\n",
            "Epoch 256/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0555 - accuracy: 0.5962 - val_loss: 0.0405 - val_accuracy: 0.7100\n",
            "Epoch 257/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0555 - accuracy: 0.5961 - val_loss: 0.0404 - val_accuracy: 0.7103\n",
            "Epoch 258/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0554 - accuracy: 0.5974 - val_loss: 0.0405 - val_accuracy: 0.7112\n",
            "Epoch 259/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0555 - accuracy: 0.5967 - val_loss: 0.0402 - val_accuracy: 0.7123\n",
            "Epoch 260/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0554 - accuracy: 0.5967 - val_loss: 0.0404 - val_accuracy: 0.7105\n",
            "Epoch 261/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0553 - accuracy: 0.5980 - val_loss: 0.0402 - val_accuracy: 0.7128\n",
            "Epoch 262/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0554 - accuracy: 0.5982 - val_loss: 0.0403 - val_accuracy: 0.7125\n",
            "Epoch 263/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0554 - accuracy: 0.5980 - val_loss: 0.0404 - val_accuracy: 0.7124\n",
            "Epoch 264/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0553 - accuracy: 0.5982 - val_loss: 0.0402 - val_accuracy: 0.7130\n",
            "Epoch 265/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0552 - accuracy: 0.5986 - val_loss: 0.0400 - val_accuracy: 0.7146\n",
            "Epoch 266/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0552 - accuracy: 0.5981 - val_loss: 0.0402 - val_accuracy: 0.7122\n",
            "Epoch 267/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0551 - accuracy: 0.5996 - val_loss: 0.0400 - val_accuracy: 0.7152\n",
            "Epoch 268/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0552 - accuracy: 0.5988 - val_loss: 0.0400 - val_accuracy: 0.7138\n",
            "Epoch 269/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0551 - accuracy: 0.6000 - val_loss: 0.0399 - val_accuracy: 0.7160\n",
            "Epoch 270/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0552 - accuracy: 0.5994 - val_loss: 0.0403 - val_accuracy: 0.7113\n",
            "Epoch 271/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0551 - accuracy: 0.5999 - val_loss: 0.0398 - val_accuracy: 0.7158\n",
            "Epoch 272/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0551 - accuracy: 0.6002 - val_loss: 0.0399 - val_accuracy: 0.7152\n",
            "Epoch 273/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0550 - accuracy: 0.6006 - val_loss: 0.0399 - val_accuracy: 0.7147\n",
            "Epoch 274/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0551 - accuracy: 0.6008 - val_loss: 0.0397 - val_accuracy: 0.7170\n",
            "Epoch 275/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0550 - accuracy: 0.6009 - val_loss: 0.0399 - val_accuracy: 0.7155\n",
            "Epoch 276/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0549 - accuracy: 0.6014 - val_loss: 0.0399 - val_accuracy: 0.7157\n",
            "Epoch 277/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0550 - accuracy: 0.6014 - val_loss: 0.0395 - val_accuracy: 0.7176\n",
            "Epoch 278/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0549 - accuracy: 0.6017 - val_loss: 0.0403 - val_accuracy: 0.7112\n",
            "Epoch 279/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0550 - accuracy: 0.6016 - val_loss: 0.0398 - val_accuracy: 0.7148\n",
            "Epoch 280/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0549 - accuracy: 0.6018 - val_loss: 0.0397 - val_accuracy: 0.7169\n",
            "Epoch 281/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0549 - accuracy: 0.6025 - val_loss: 0.0396 - val_accuracy: 0.7162\n",
            "Epoch 282/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0548 - accuracy: 0.6038 - val_loss: 0.0394 - val_accuracy: 0.7192\n",
            "Epoch 283/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0548 - accuracy: 0.6033 - val_loss: 0.0398 - val_accuracy: 0.7156\n",
            "Epoch 284/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0548 - accuracy: 0.6030 - val_loss: 0.0395 - val_accuracy: 0.7186\n",
            "Epoch 285/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0548 - accuracy: 0.6029 - val_loss: 0.0397 - val_accuracy: 0.7165\n",
            "Epoch 286/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0548 - accuracy: 0.6028 - val_loss: 0.0396 - val_accuracy: 0.7185\n",
            "Epoch 287/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0547 - accuracy: 0.6035 - val_loss: 0.0392 - val_accuracy: 0.7204\n",
            "Epoch 288/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0548 - accuracy: 0.6036 - val_loss: 0.0396 - val_accuracy: 0.7177\n",
            "Epoch 289/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0547 - accuracy: 0.6047 - val_loss: 0.0394 - val_accuracy: 0.7192\n",
            "Epoch 290/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0546 - accuracy: 0.6056 - val_loss: 0.0395 - val_accuracy: 0.7183\n",
            "Epoch 291/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0546 - accuracy: 0.6051 - val_loss: 0.0392 - val_accuracy: 0.7224\n",
            "Epoch 292/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0546 - accuracy: 0.6049 - val_loss: 0.0396 - val_accuracy: 0.7165\n",
            "Epoch 293/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0547 - accuracy: 0.6044 - val_loss: 0.0393 - val_accuracy: 0.7196\n",
            "Epoch 294/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0546 - accuracy: 0.6050 - val_loss: 0.0391 - val_accuracy: 0.7213\n",
            "Epoch 295/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0547 - accuracy: 0.6042 - val_loss: 0.0392 - val_accuracy: 0.7208\n",
            "Epoch 296/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0546 - accuracy: 0.6050 - val_loss: 0.0392 - val_accuracy: 0.7216\n",
            "Epoch 297/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0545 - accuracy: 0.6056 - val_loss: 0.0390 - val_accuracy: 0.7224\n",
            "Epoch 298/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0545 - accuracy: 0.6059 - val_loss: 0.0390 - val_accuracy: 0.7219\n",
            "Epoch 299/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0545 - accuracy: 0.6063 - val_loss: 0.0390 - val_accuracy: 0.7235\n",
            "Epoch 300/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0544 - accuracy: 0.6065 - val_loss: 0.0391 - val_accuracy: 0.7213\n",
            "Epoch 301/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0545 - accuracy: 0.6062 - val_loss: 0.0390 - val_accuracy: 0.7237\n",
            "Epoch 302/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0545 - accuracy: 0.6063 - val_loss: 0.0390 - val_accuracy: 0.7227\n",
            "Epoch 303/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0544 - accuracy: 0.6071 - val_loss: 0.0389 - val_accuracy: 0.7242\n",
            "Epoch 304/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0543 - accuracy: 0.6071 - val_loss: 0.0392 - val_accuracy: 0.7217\n",
            "Epoch 305/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0542 - accuracy: 0.6081 - val_loss: 0.0391 - val_accuracy: 0.7217\n",
            "Epoch 306/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0543 - accuracy: 0.6073 - val_loss: 0.0389 - val_accuracy: 0.7237\n",
            "Epoch 307/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0543 - accuracy: 0.6081 - val_loss: 0.0388 - val_accuracy: 0.7241\n",
            "Epoch 308/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0543 - accuracy: 0.6080 - val_loss: 0.0389 - val_accuracy: 0.7231\n",
            "Epoch 309/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0542 - accuracy: 0.6089 - val_loss: 0.0386 - val_accuracy: 0.7267\n",
            "Epoch 310/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0542 - accuracy: 0.6088 - val_loss: 0.0389 - val_accuracy: 0.7230\n",
            "Epoch 311/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0541 - accuracy: 0.6093 - val_loss: 0.0388 - val_accuracy: 0.7238\n",
            "Epoch 312/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0542 - accuracy: 0.6093 - val_loss: 0.0387 - val_accuracy: 0.7261\n",
            "Epoch 313/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0542 - accuracy: 0.6087 - val_loss: 0.0388 - val_accuracy: 0.7248\n",
            "Epoch 314/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0542 - accuracy: 0.6094 - val_loss: 0.0386 - val_accuracy: 0.7277\n",
            "Epoch 315/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0541 - accuracy: 0.6095 - val_loss: 0.0384 - val_accuracy: 0.7270\n",
            "Epoch 316/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0541 - accuracy: 0.6093 - val_loss: 0.0385 - val_accuracy: 0.7270\n",
            "Epoch 317/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0541 - accuracy: 0.6103 - val_loss: 0.0386 - val_accuracy: 0.7273\n",
            "Epoch 318/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0540 - accuracy: 0.6104 - val_loss: 0.0383 - val_accuracy: 0.7293\n",
            "Epoch 319/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0541 - accuracy: 0.6104 - val_loss: 0.0386 - val_accuracy: 0.7261\n",
            "Epoch 320/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0541 - accuracy: 0.6099 - val_loss: 0.0389 - val_accuracy: 0.7242\n",
            "Epoch 321/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0541 - accuracy: 0.6104 - val_loss: 0.0383 - val_accuracy: 0.7302\n",
            "Epoch 322/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0540 - accuracy: 0.6112 - val_loss: 0.0381 - val_accuracy: 0.7304\n",
            "Epoch 323/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0540 - accuracy: 0.6107 - val_loss: 0.0382 - val_accuracy: 0.7299\n",
            "Epoch 324/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0539 - accuracy: 0.6113 - val_loss: 0.0386 - val_accuracy: 0.7260\n",
            "Epoch 325/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0539 - accuracy: 0.6111 - val_loss: 0.0384 - val_accuracy: 0.7272\n",
            "Epoch 326/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0539 - accuracy: 0.6116 - val_loss: 0.0383 - val_accuracy: 0.7280\n",
            "Epoch 327/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0538 - accuracy: 0.6123 - val_loss: 0.0382 - val_accuracy: 0.7284\n",
            "Epoch 328/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0539 - accuracy: 0.6126 - val_loss: 0.0380 - val_accuracy: 0.7316\n",
            "Epoch 329/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0539 - accuracy: 0.6116 - val_loss: 0.0383 - val_accuracy: 0.7291\n",
            "Epoch 330/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0538 - accuracy: 0.6122 - val_loss: 0.0381 - val_accuracy: 0.7300\n",
            "Epoch 331/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0539 - accuracy: 0.6119 - val_loss: 0.0382 - val_accuracy: 0.7301\n",
            "Epoch 332/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0538 - accuracy: 0.6131 - val_loss: 0.0380 - val_accuracy: 0.7315\n",
            "Epoch 333/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0538 - accuracy: 0.6123 - val_loss: 0.0380 - val_accuracy: 0.7313\n",
            "Epoch 334/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0537 - accuracy: 0.6139 - val_loss: 0.0380 - val_accuracy: 0.7301\n",
            "Epoch 335/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0538 - accuracy: 0.6130 - val_loss: 0.0378 - val_accuracy: 0.7333\n",
            "Epoch 336/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0538 - accuracy: 0.6133 - val_loss: 0.0380 - val_accuracy: 0.7310\n",
            "Epoch 337/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0536 - accuracy: 0.6150 - val_loss: 0.0378 - val_accuracy: 0.7326\n",
            "Epoch 338/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0537 - accuracy: 0.6132 - val_loss: 0.0379 - val_accuracy: 0.7314\n",
            "Epoch 339/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0537 - accuracy: 0.6142 - val_loss: 0.0378 - val_accuracy: 0.7314\n",
            "Epoch 340/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0537 - accuracy: 0.6143 - val_loss: 0.0382 - val_accuracy: 0.7303\n",
            "Epoch 341/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0537 - accuracy: 0.6138 - val_loss: 0.0378 - val_accuracy: 0.7327\n",
            "Epoch 342/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0536 - accuracy: 0.6142 - val_loss: 0.0379 - val_accuracy: 0.7336\n",
            "Epoch 343/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0536 - accuracy: 0.6155 - val_loss: 0.0378 - val_accuracy: 0.7319\n",
            "Epoch 344/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0536 - accuracy: 0.6143 - val_loss: 0.0378 - val_accuracy: 0.7327\n",
            "Epoch 345/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0536 - accuracy: 0.6150 - val_loss: 0.0375 - val_accuracy: 0.7349\n",
            "Epoch 346/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0535 - accuracy: 0.6149 - val_loss: 0.0378 - val_accuracy: 0.7330\n",
            "Epoch 347/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0535 - accuracy: 0.6160 - val_loss: 0.0376 - val_accuracy: 0.7350\n",
            "Epoch 348/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0535 - accuracy: 0.6160 - val_loss: 0.0376 - val_accuracy: 0.7326\n",
            "Epoch 349/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0535 - accuracy: 0.6154 - val_loss: 0.0374 - val_accuracy: 0.7354\n",
            "Epoch 350/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0535 - accuracy: 0.6159 - val_loss: 0.0373 - val_accuracy: 0.7364\n",
            "Epoch 351/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0535 - accuracy: 0.6159 - val_loss: 0.0373 - val_accuracy: 0.7362\n",
            "Epoch 352/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0534 - accuracy: 0.6172 - val_loss: 0.0376 - val_accuracy: 0.7330\n",
            "Epoch 353/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0534 - accuracy: 0.6175 - val_loss: 0.0376 - val_accuracy: 0.7350\n",
            "Epoch 354/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0534 - accuracy: 0.6175 - val_loss: 0.0375 - val_accuracy: 0.7362\n",
            "Epoch 355/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0534 - accuracy: 0.6162 - val_loss: 0.0375 - val_accuracy: 0.7350\n",
            "Epoch 356/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0534 - accuracy: 0.6174 - val_loss: 0.0376 - val_accuracy: 0.7343\n",
            "Epoch 357/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0534 - accuracy: 0.6170 - val_loss: 0.0377 - val_accuracy: 0.7342\n",
            "Epoch 358/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0533 - accuracy: 0.6176 - val_loss: 0.0372 - val_accuracy: 0.7356\n",
            "Epoch 359/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0533 - accuracy: 0.6177 - val_loss: 0.0371 - val_accuracy: 0.7386\n",
            "Epoch 360/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0532 - accuracy: 0.6178 - val_loss: 0.0377 - val_accuracy: 0.7350\n",
            "Epoch 361/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0533 - accuracy: 0.6175 - val_loss: 0.0374 - val_accuracy: 0.7374\n",
            "Epoch 362/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0533 - accuracy: 0.6172 - val_loss: 0.0373 - val_accuracy: 0.7369\n",
            "Epoch 363/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0533 - accuracy: 0.6178 - val_loss: 0.0374 - val_accuracy: 0.7362\n",
            "Epoch 364/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0532 - accuracy: 0.6179 - val_loss: 0.0372 - val_accuracy: 0.7385\n",
            "Epoch 365/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0532 - accuracy: 0.6186 - val_loss: 0.0371 - val_accuracy: 0.7382\n",
            "Epoch 366/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0532 - accuracy: 0.6187 - val_loss: 0.0372 - val_accuracy: 0.7367\n",
            "Epoch 367/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0531 - accuracy: 0.6194 - val_loss: 0.0370 - val_accuracy: 0.7385\n",
            "Epoch 368/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0531 - accuracy: 0.6194 - val_loss: 0.0372 - val_accuracy: 0.7386\n",
            "Epoch 369/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0531 - accuracy: 0.6194 - val_loss: 0.0370 - val_accuracy: 0.7384\n",
            "Epoch 370/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0531 - accuracy: 0.6182 - val_loss: 0.0371 - val_accuracy: 0.7380\n",
            "Epoch 371/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0530 - accuracy: 0.6205 - val_loss: 0.0370 - val_accuracy: 0.7386\n",
            "Epoch 372/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0531 - accuracy: 0.6192 - val_loss: 0.0369 - val_accuracy: 0.7400\n",
            "Epoch 373/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0531 - accuracy: 0.6199 - val_loss: 0.0371 - val_accuracy: 0.7391\n",
            "Epoch 374/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0531 - accuracy: 0.6200 - val_loss: 0.0370 - val_accuracy: 0.7379\n",
            "Epoch 375/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0531 - accuracy: 0.6196 - val_loss: 0.0368 - val_accuracy: 0.7399\n",
            "Epoch 376/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0529 - accuracy: 0.6211 - val_loss: 0.0367 - val_accuracy: 0.7416\n",
            "Epoch 377/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0531 - accuracy: 0.6195 - val_loss: 0.0368 - val_accuracy: 0.7411\n",
            "Epoch 378/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0530 - accuracy: 0.6204 - val_loss: 0.0368 - val_accuracy: 0.7418\n",
            "Epoch 379/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0530 - accuracy: 0.6208 - val_loss: 0.0369 - val_accuracy: 0.7399\n",
            "Epoch 380/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0530 - accuracy: 0.6204 - val_loss: 0.0367 - val_accuracy: 0.7420\n",
            "Epoch 381/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0529 - accuracy: 0.6206 - val_loss: 0.0366 - val_accuracy: 0.7425\n",
            "Epoch 382/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0529 - accuracy: 0.6214 - val_loss: 0.0365 - val_accuracy: 0.7432\n",
            "Epoch 383/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0528 - accuracy: 0.6211 - val_loss: 0.0366 - val_accuracy: 0.7416\n",
            "Epoch 384/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0529 - accuracy: 0.6207 - val_loss: 0.0367 - val_accuracy: 0.7401\n",
            "Epoch 385/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0528 - accuracy: 0.6213 - val_loss: 0.0367 - val_accuracy: 0.7428\n",
            "Epoch 386/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0528 - accuracy: 0.6217 - val_loss: 0.0366 - val_accuracy: 0.7417\n",
            "Epoch 387/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0529 - accuracy: 0.6223 - val_loss: 0.0367 - val_accuracy: 0.7411\n",
            "Epoch 388/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0528 - accuracy: 0.6225 - val_loss: 0.0367 - val_accuracy: 0.7421\n",
            "Epoch 389/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0527 - accuracy: 0.6231 - val_loss: 0.0364 - val_accuracy: 0.7439\n",
            "Epoch 390/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0528 - accuracy: 0.6235 - val_loss: 0.0365 - val_accuracy: 0.7433\n",
            "Epoch 391/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0527 - accuracy: 0.6223 - val_loss: 0.0366 - val_accuracy: 0.7416\n",
            "Epoch 392/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0528 - accuracy: 0.6235 - val_loss: 0.0366 - val_accuracy: 0.7425\n",
            "Epoch 393/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0528 - accuracy: 0.6228 - val_loss: 0.0366 - val_accuracy: 0.7422\n",
            "Epoch 394/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0528 - accuracy: 0.6228 - val_loss: 0.0366 - val_accuracy: 0.7418\n",
            "Epoch 395/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0528 - accuracy: 0.6221 - val_loss: 0.0365 - val_accuracy: 0.7440\n",
            "Epoch 396/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0526 - accuracy: 0.6246 - val_loss: 0.0364 - val_accuracy: 0.7434\n",
            "Epoch 397/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0527 - accuracy: 0.6230 - val_loss: 0.0368 - val_accuracy: 0.7413\n",
            "Epoch 398/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0526 - accuracy: 0.6244 - val_loss: 0.0367 - val_accuracy: 0.7424\n",
            "Epoch 399/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0526 - accuracy: 0.6244 - val_loss: 0.0365 - val_accuracy: 0.7428\n",
            "Epoch 400/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0526 - accuracy: 0.6242 - val_loss: 0.0365 - val_accuracy: 0.7427\n",
            "Epoch 401/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0526 - accuracy: 0.6237 - val_loss: 0.0362 - val_accuracy: 0.7447\n",
            "Epoch 402/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0526 - accuracy: 0.6246 - val_loss: 0.0363 - val_accuracy: 0.7440\n",
            "Epoch 403/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0525 - accuracy: 0.6253 - val_loss: 0.0361 - val_accuracy: 0.7463\n",
            "Epoch 404/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0525 - accuracy: 0.6252 - val_loss: 0.0364 - val_accuracy: 0.7431\n",
            "Epoch 405/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0526 - accuracy: 0.6250 - val_loss: 0.0362 - val_accuracy: 0.7458\n",
            "Epoch 406/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0524 - accuracy: 0.6257 - val_loss: 0.0364 - val_accuracy: 0.7431\n",
            "Epoch 407/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0524 - accuracy: 0.6260 - val_loss: 0.0363 - val_accuracy: 0.7446\n",
            "Epoch 408/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0525 - accuracy: 0.6254 - val_loss: 0.0359 - val_accuracy: 0.7484\n",
            "Epoch 409/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0526 - accuracy: 0.6243 - val_loss: 0.0363 - val_accuracy: 0.7445\n",
            "Epoch 410/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0524 - accuracy: 0.6260 - val_loss: 0.0361 - val_accuracy: 0.7468\n",
            "Epoch 411/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0525 - accuracy: 0.6257 - val_loss: 0.0361 - val_accuracy: 0.7463\n",
            "Epoch 412/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0524 - accuracy: 0.6254 - val_loss: 0.0359 - val_accuracy: 0.7485\n",
            "Epoch 413/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0524 - accuracy: 0.6254 - val_loss: 0.0359 - val_accuracy: 0.7494\n",
            "Epoch 414/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0524 - accuracy: 0.6258 - val_loss: 0.0361 - val_accuracy: 0.7455\n",
            "Epoch 415/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0524 - accuracy: 0.6266 - val_loss: 0.0361 - val_accuracy: 0.7465\n",
            "Epoch 416/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0524 - accuracy: 0.6268 - val_loss: 0.0357 - val_accuracy: 0.7498\n",
            "Epoch 417/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0522 - accuracy: 0.6279 - val_loss: 0.0358 - val_accuracy: 0.7487\n",
            "Epoch 418/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0523 - accuracy: 0.6267 - val_loss: 0.0359 - val_accuracy: 0.7480\n",
            "Epoch 419/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0523 - accuracy: 0.6269 - val_loss: 0.0359 - val_accuracy: 0.7482\n",
            "Epoch 420/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0523 - accuracy: 0.6274 - val_loss: 0.0358 - val_accuracy: 0.7490\n",
            "Epoch 421/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0523 - accuracy: 0.6271 - val_loss: 0.0357 - val_accuracy: 0.7492\n",
            "Epoch 422/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0523 - accuracy: 0.6266 - val_loss: 0.0360 - val_accuracy: 0.7470\n",
            "Epoch 423/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0522 - accuracy: 0.6280 - val_loss: 0.0359 - val_accuracy: 0.7489\n",
            "Epoch 424/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0523 - accuracy: 0.6276 - val_loss: 0.0360 - val_accuracy: 0.7472\n",
            "Epoch 425/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0522 - accuracy: 0.6275 - val_loss: 0.0360 - val_accuracy: 0.7479\n",
            "Epoch 426/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0521 - accuracy: 0.6292 - val_loss: 0.0357 - val_accuracy: 0.7496\n",
            "Epoch 427/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0522 - accuracy: 0.6274 - val_loss: 0.0358 - val_accuracy: 0.7482\n",
            "Epoch 428/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0522 - accuracy: 0.6279 - val_loss: 0.0357 - val_accuracy: 0.7495\n",
            "Epoch 429/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0522 - accuracy: 0.6277 - val_loss: 0.0356 - val_accuracy: 0.7507\n",
            "Epoch 430/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0522 - accuracy: 0.6280 - val_loss: 0.0356 - val_accuracy: 0.7501\n",
            "Epoch 431/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0522 - accuracy: 0.6276 - val_loss: 0.0357 - val_accuracy: 0.7501\n",
            "Epoch 432/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0521 - accuracy: 0.6290 - val_loss: 0.0357 - val_accuracy: 0.7499\n",
            "Epoch 433/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0522 - accuracy: 0.6285 - val_loss: 0.0357 - val_accuracy: 0.7497\n",
            "Epoch 434/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0521 - accuracy: 0.6296 - val_loss: 0.0355 - val_accuracy: 0.7508\n",
            "Epoch 435/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0521 - accuracy: 0.6288 - val_loss: 0.0352 - val_accuracy: 0.7535\n",
            "Epoch 436/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0521 - accuracy: 0.6288 - val_loss: 0.0355 - val_accuracy: 0.7515\n",
            "Epoch 437/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0520 - accuracy: 0.6299 - val_loss: 0.0355 - val_accuracy: 0.7510\n",
            "Epoch 438/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0521 - accuracy: 0.6290 - val_loss: 0.0353 - val_accuracy: 0.7524\n",
            "Epoch 439/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0519 - accuracy: 0.6303 - val_loss: 0.0355 - val_accuracy: 0.7509\n",
            "Epoch 440/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0520 - accuracy: 0.6295 - val_loss: 0.0354 - val_accuracy: 0.7532\n",
            "Epoch 441/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0520 - accuracy: 0.6290 - val_loss: 0.0353 - val_accuracy: 0.7544\n",
            "Epoch 442/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0520 - accuracy: 0.6297 - val_loss: 0.0353 - val_accuracy: 0.7531\n",
            "Epoch 443/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0519 - accuracy: 0.6306 - val_loss: 0.0353 - val_accuracy: 0.7524\n",
            "Epoch 444/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0520 - accuracy: 0.6301 - val_loss: 0.0356 - val_accuracy: 0.7521\n",
            "Epoch 445/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0519 - accuracy: 0.6306 - val_loss: 0.0353 - val_accuracy: 0.7513\n",
            "Epoch 446/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0520 - accuracy: 0.6292 - val_loss: 0.0351 - val_accuracy: 0.7544\n",
            "Epoch 447/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0519 - accuracy: 0.6305 - val_loss: 0.0354 - val_accuracy: 0.7524\n",
            "Epoch 448/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0518 - accuracy: 0.6315 - val_loss: 0.0353 - val_accuracy: 0.7525\n",
            "Epoch 449/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0518 - accuracy: 0.6319 - val_loss: 0.0353 - val_accuracy: 0.7533\n",
            "Epoch 450/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0519 - accuracy: 0.6311 - val_loss: 0.0353 - val_accuracy: 0.7539\n",
            "Epoch 451/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0518 - accuracy: 0.6316 - val_loss: 0.0354 - val_accuracy: 0.7519\n",
            "Epoch 452/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0518 - accuracy: 0.6315 - val_loss: 0.0354 - val_accuracy: 0.7509\n",
            "Epoch 453/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0518 - accuracy: 0.6316 - val_loss: 0.0349 - val_accuracy: 0.7552\n",
            "Epoch 454/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0518 - accuracy: 0.6319 - val_loss: 0.0351 - val_accuracy: 0.7548\n",
            "Epoch 455/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0519 - accuracy: 0.6312 - val_loss: 0.0351 - val_accuracy: 0.7546\n",
            "Epoch 456/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0517 - accuracy: 0.6328 - val_loss: 0.0350 - val_accuracy: 0.7554\n",
            "Epoch 457/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0517 - accuracy: 0.6327 - val_loss: 0.0352 - val_accuracy: 0.7532\n",
            "Epoch 458/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0517 - accuracy: 0.6320 - val_loss: 0.0350 - val_accuracy: 0.7557\n",
            "Epoch 459/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0518 - accuracy: 0.6324 - val_loss: 0.0351 - val_accuracy: 0.7549\n",
            "Epoch 460/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0519 - accuracy: 0.6314 - val_loss: 0.0351 - val_accuracy: 0.7544\n",
            "Epoch 461/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0516 - accuracy: 0.6336 - val_loss: 0.0348 - val_accuracy: 0.7570\n",
            "Epoch 462/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0517 - accuracy: 0.6330 - val_loss: 0.0352 - val_accuracy: 0.7523\n",
            "Epoch 463/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0516 - accuracy: 0.6335 - val_loss: 0.0350 - val_accuracy: 0.7565\n",
            "Epoch 464/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0517 - accuracy: 0.6325 - val_loss: 0.0350 - val_accuracy: 0.7553\n",
            "Epoch 465/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0517 - accuracy: 0.6325 - val_loss: 0.0350 - val_accuracy: 0.7557\n",
            "Epoch 466/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0517 - accuracy: 0.6332 - val_loss: 0.0349 - val_accuracy: 0.7574\n",
            "Epoch 467/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0516 - accuracy: 0.6345 - val_loss: 0.0349 - val_accuracy: 0.7559\n",
            "Epoch 468/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0515 - accuracy: 0.6340 - val_loss: 0.0347 - val_accuracy: 0.7577\n",
            "Epoch 469/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0516 - accuracy: 0.6335 - val_loss: 0.0349 - val_accuracy: 0.7568\n",
            "Epoch 470/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0515 - accuracy: 0.6344 - val_loss: 0.0349 - val_accuracy: 0.7554\n",
            "Epoch 471/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0515 - accuracy: 0.6348 - val_loss: 0.0347 - val_accuracy: 0.7576\n",
            "Epoch 472/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0515 - accuracy: 0.6344 - val_loss: 0.0346 - val_accuracy: 0.7587\n",
            "Epoch 473/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0516 - accuracy: 0.6334 - val_loss: 0.0349 - val_accuracy: 0.7557\n",
            "Epoch 474/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0516 - accuracy: 0.6341 - val_loss: 0.0348 - val_accuracy: 0.7555\n",
            "Epoch 475/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0515 - accuracy: 0.6350 - val_loss: 0.0346 - val_accuracy: 0.7592\n",
            "Epoch 476/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0515 - accuracy: 0.6347 - val_loss: 0.0348 - val_accuracy: 0.7568\n",
            "Epoch 477/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0514 - accuracy: 0.6351 - val_loss: 0.0349 - val_accuracy: 0.7560\n",
            "Epoch 478/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0514 - accuracy: 0.6351 - val_loss: 0.0349 - val_accuracy: 0.7561\n",
            "Epoch 479/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0515 - accuracy: 0.6355 - val_loss: 0.0346 - val_accuracy: 0.7583\n",
            "Epoch 480/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0514 - accuracy: 0.6351 - val_loss: 0.0346 - val_accuracy: 0.7578\n",
            "Epoch 481/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0513 - accuracy: 0.6354 - val_loss: 0.0345 - val_accuracy: 0.7595\n",
            "Epoch 482/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0514 - accuracy: 0.6350 - val_loss: 0.0346 - val_accuracy: 0.7582\n",
            "Epoch 483/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0514 - accuracy: 0.6361 - val_loss: 0.0346 - val_accuracy: 0.7588\n",
            "Epoch 484/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0514 - accuracy: 0.6356 - val_loss: 0.0345 - val_accuracy: 0.7592\n",
            "Epoch 485/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0514 - accuracy: 0.6357 - val_loss: 0.0346 - val_accuracy: 0.7590\n",
            "Epoch 486/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0513 - accuracy: 0.6365 - val_loss: 0.0345 - val_accuracy: 0.7601\n",
            "Epoch 487/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0513 - accuracy: 0.6355 - val_loss: 0.0345 - val_accuracy: 0.7594\n",
            "Epoch 488/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0513 - accuracy: 0.6357 - val_loss: 0.0346 - val_accuracy: 0.7594\n",
            "Epoch 489/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0513 - accuracy: 0.6362 - val_loss: 0.0345 - val_accuracy: 0.7592\n",
            "Epoch 490/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0513 - accuracy: 0.6371 - val_loss: 0.0345 - val_accuracy: 0.7590\n",
            "Epoch 491/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0513 - accuracy: 0.6372 - val_loss: 0.0347 - val_accuracy: 0.7584\n",
            "Epoch 492/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0513 - accuracy: 0.6368 - val_loss: 0.0347 - val_accuracy: 0.7572\n",
            "Epoch 493/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0514 - accuracy: 0.6359 - val_loss: 0.0345 - val_accuracy: 0.7596\n",
            "Epoch 494/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0512 - accuracy: 0.6365 - val_loss: 0.0344 - val_accuracy: 0.7597\n",
            "Epoch 495/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0513 - accuracy: 0.6365 - val_loss: 0.0343 - val_accuracy: 0.7606\n",
            "Epoch 496/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0513 - accuracy: 0.6369 - val_loss: 0.0343 - val_accuracy: 0.7603\n",
            "Epoch 497/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0512 - accuracy: 0.6375 - val_loss: 0.0342 - val_accuracy: 0.7613\n",
            "Epoch 498/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0512 - accuracy: 0.6374 - val_loss: 0.0341 - val_accuracy: 0.7617\n",
            "Epoch 499/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0512 - accuracy: 0.6369 - val_loss: 0.0343 - val_accuracy: 0.7607\n",
            "Epoch 500/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0511 - accuracy: 0.6375 - val_loss: 0.0345 - val_accuracy: 0.7592\n",
            "Epoch 501/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0512 - accuracy: 0.6371 - val_loss: 0.0344 - val_accuracy: 0.7599\n",
            "Epoch 502/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0512 - accuracy: 0.6373 - val_loss: 0.0341 - val_accuracy: 0.7626\n",
            "Epoch 503/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0512 - accuracy: 0.6374 - val_loss: 0.0344 - val_accuracy: 0.7593\n",
            "Epoch 504/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0511 - accuracy: 0.6377 - val_loss: 0.0343 - val_accuracy: 0.7606\n",
            "Epoch 505/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0510 - accuracy: 0.6386 - val_loss: 0.0341 - val_accuracy: 0.7634\n",
            "Epoch 506/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0511 - accuracy: 0.6378 - val_loss: 0.0341 - val_accuracy: 0.7626\n",
            "Epoch 507/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0511 - accuracy: 0.6384 - val_loss: 0.0343 - val_accuracy: 0.7609\n",
            "Epoch 508/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0511 - accuracy: 0.6390 - val_loss: 0.0341 - val_accuracy: 0.7622\n",
            "Epoch 509/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0511 - accuracy: 0.6386 - val_loss: 0.0341 - val_accuracy: 0.7640\n",
            "Epoch 510/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0510 - accuracy: 0.6388 - val_loss: 0.0340 - val_accuracy: 0.7629\n",
            "Epoch 511/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0511 - accuracy: 0.6387 - val_loss: 0.0341 - val_accuracy: 0.7623\n",
            "Epoch 512/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0510 - accuracy: 0.6386 - val_loss: 0.0340 - val_accuracy: 0.7630\n",
            "Epoch 513/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0510 - accuracy: 0.6397 - val_loss: 0.0341 - val_accuracy: 0.7632\n",
            "Epoch 514/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0509 - accuracy: 0.6398 - val_loss: 0.0341 - val_accuracy: 0.7624\n",
            "Epoch 515/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0510 - accuracy: 0.6392 - val_loss: 0.0341 - val_accuracy: 0.7624\n",
            "Epoch 516/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0510 - accuracy: 0.6393 - val_loss: 0.0339 - val_accuracy: 0.7637\n",
            "Epoch 517/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0510 - accuracy: 0.6392 - val_loss: 0.0340 - val_accuracy: 0.7633\n",
            "Epoch 518/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0509 - accuracy: 0.6402 - val_loss: 0.0340 - val_accuracy: 0.7625\n",
            "Epoch 519/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0509 - accuracy: 0.6406 - val_loss: 0.0340 - val_accuracy: 0.7631\n",
            "Epoch 520/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0509 - accuracy: 0.6399 - val_loss: 0.0339 - val_accuracy: 0.7635\n",
            "Epoch 521/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0508 - accuracy: 0.6410 - val_loss: 0.0338 - val_accuracy: 0.7638\n",
            "Epoch 522/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0509 - accuracy: 0.6391 - val_loss: 0.0338 - val_accuracy: 0.7653\n",
            "Epoch 523/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0509 - accuracy: 0.6398 - val_loss: 0.0339 - val_accuracy: 0.7639\n",
            "Epoch 524/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0508 - accuracy: 0.6411 - val_loss: 0.0339 - val_accuracy: 0.7642\n",
            "Epoch 525/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0509 - accuracy: 0.6405 - val_loss: 0.0339 - val_accuracy: 0.7627\n",
            "Epoch 526/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0508 - accuracy: 0.6409 - val_loss: 0.0339 - val_accuracy: 0.7639\n",
            "Epoch 527/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0509 - accuracy: 0.6397 - val_loss: 0.0341 - val_accuracy: 0.7625\n",
            "Epoch 528/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0509 - accuracy: 0.6403 - val_loss: 0.0338 - val_accuracy: 0.7649\n",
            "Epoch 529/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0509 - accuracy: 0.6408 - val_loss: 0.0337 - val_accuracy: 0.7651\n",
            "Epoch 530/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0508 - accuracy: 0.6412 - val_loss: 0.0337 - val_accuracy: 0.7666\n",
            "Epoch 531/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0508 - accuracy: 0.6409 - val_loss: 0.0337 - val_accuracy: 0.7659\n",
            "Epoch 532/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0508 - accuracy: 0.6408 - val_loss: 0.0338 - val_accuracy: 0.7643\n",
            "Epoch 533/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0507 - accuracy: 0.6421 - val_loss: 0.0335 - val_accuracy: 0.7666\n",
            "Epoch 534/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0508 - accuracy: 0.6414 - val_loss: 0.0338 - val_accuracy: 0.7660\n",
            "Epoch 535/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0507 - accuracy: 0.6421 - val_loss: 0.0336 - val_accuracy: 0.7657\n",
            "Epoch 536/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0507 - accuracy: 0.6416 - val_loss: 0.0340 - val_accuracy: 0.7630\n",
            "Epoch 537/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0507 - accuracy: 0.6428 - val_loss: 0.0336 - val_accuracy: 0.7670\n",
            "Epoch 538/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0507 - accuracy: 0.6422 - val_loss: 0.0336 - val_accuracy: 0.7661\n",
            "Epoch 539/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0508 - accuracy: 0.6413 - val_loss: 0.0338 - val_accuracy: 0.7648\n",
            "Epoch 540/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0506 - accuracy: 0.6422 - val_loss: 0.0335 - val_accuracy: 0.7673\n",
            "Epoch 541/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0506 - accuracy: 0.6427 - val_loss: 0.0336 - val_accuracy: 0.7660\n",
            "Epoch 542/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0507 - accuracy: 0.6421 - val_loss: 0.0336 - val_accuracy: 0.7659\n",
            "Epoch 543/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0507 - accuracy: 0.6425 - val_loss: 0.0336 - val_accuracy: 0.7668\n",
            "Epoch 544/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0506 - accuracy: 0.6432 - val_loss: 0.0337 - val_accuracy: 0.7654\n",
            "Epoch 545/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0506 - accuracy: 0.6431 - val_loss: 0.0336 - val_accuracy: 0.7660\n",
            "Epoch 546/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0506 - accuracy: 0.6428 - val_loss: 0.0336 - val_accuracy: 0.7651\n",
            "Epoch 547/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0506 - accuracy: 0.6425 - val_loss: 0.0337 - val_accuracy: 0.7669\n",
            "Epoch 548/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0507 - accuracy: 0.6426 - val_loss: 0.0337 - val_accuracy: 0.7650\n",
            "Epoch 549/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0506 - accuracy: 0.6434 - val_loss: 0.0334 - val_accuracy: 0.7680\n",
            "Epoch 550/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0505 - accuracy: 0.6441 - val_loss: 0.0333 - val_accuracy: 0.7681\n",
            "Epoch 551/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0505 - accuracy: 0.6443 - val_loss: 0.0333 - val_accuracy: 0.7688\n",
            "Epoch 552/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0505 - accuracy: 0.6444 - val_loss: 0.0337 - val_accuracy: 0.7667\n",
            "Epoch 553/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0505 - accuracy: 0.6435 - val_loss: 0.0334 - val_accuracy: 0.7666\n",
            "Epoch 554/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0505 - accuracy: 0.6444 - val_loss: 0.0335 - val_accuracy: 0.7675\n",
            "Epoch 555/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0505 - accuracy: 0.6434 - val_loss: 0.0335 - val_accuracy: 0.7679\n",
            "Epoch 556/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0506 - accuracy: 0.6434 - val_loss: 0.0333 - val_accuracy: 0.7693\n",
            "Epoch 557/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0505 - accuracy: 0.6439 - val_loss: 0.0333 - val_accuracy: 0.7699\n",
            "Epoch 558/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0504 - accuracy: 0.6444 - val_loss: 0.0331 - val_accuracy: 0.7690\n",
            "Epoch 559/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0504 - accuracy: 0.6441 - val_loss: 0.0335 - val_accuracy: 0.7671\n",
            "Epoch 560/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0504 - accuracy: 0.6457 - val_loss: 0.0333 - val_accuracy: 0.7683\n",
            "Epoch 561/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0504 - accuracy: 0.6447 - val_loss: 0.0332 - val_accuracy: 0.7701\n",
            "Epoch 562/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0504 - accuracy: 0.6441 - val_loss: 0.0332 - val_accuracy: 0.7692\n",
            "Epoch 563/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0505 - accuracy: 0.6438 - val_loss: 0.0332 - val_accuracy: 0.7704\n",
            "Epoch 564/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0504 - accuracy: 0.6442 - val_loss: 0.0334 - val_accuracy: 0.7684\n",
            "Epoch 565/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0505 - accuracy: 0.6440 - val_loss: 0.0330 - val_accuracy: 0.7709\n",
            "Epoch 566/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0504 - accuracy: 0.6453 - val_loss: 0.0332 - val_accuracy: 0.7699\n",
            "Epoch 567/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0505 - accuracy: 0.6447 - val_loss: 0.0331 - val_accuracy: 0.7705\n",
            "Epoch 568/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0504 - accuracy: 0.6448 - val_loss: 0.0332 - val_accuracy: 0.7691\n",
            "Epoch 569/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0504 - accuracy: 0.6451 - val_loss: 0.0331 - val_accuracy: 0.7705\n",
            "Epoch 570/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0503 - accuracy: 0.6463 - val_loss: 0.0331 - val_accuracy: 0.7697\n",
            "Epoch 571/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0504 - accuracy: 0.6442 - val_loss: 0.0330 - val_accuracy: 0.7706\n",
            "Epoch 572/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0504 - accuracy: 0.6448 - val_loss: 0.0332 - val_accuracy: 0.7700\n",
            "Epoch 573/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0503 - accuracy: 0.6460 - val_loss: 0.0330 - val_accuracy: 0.7701\n",
            "Epoch 574/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0503 - accuracy: 0.6461 - val_loss: 0.0333 - val_accuracy: 0.7691\n",
            "Epoch 575/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0503 - accuracy: 0.6458 - val_loss: 0.0331 - val_accuracy: 0.7685\n",
            "Epoch 576/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0504 - accuracy: 0.6458 - val_loss: 0.0330 - val_accuracy: 0.7706\n",
            "Epoch 577/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0502 - accuracy: 0.6467 - val_loss: 0.0329 - val_accuracy: 0.7717\n",
            "Epoch 578/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0502 - accuracy: 0.6476 - val_loss: 0.0331 - val_accuracy: 0.7708\n",
            "Epoch 579/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0502 - accuracy: 0.6470 - val_loss: 0.0330 - val_accuracy: 0.7708\n",
            "Epoch 580/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0503 - accuracy: 0.6458 - val_loss: 0.0329 - val_accuracy: 0.7725\n",
            "Epoch 581/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0502 - accuracy: 0.6457 - val_loss: 0.0330 - val_accuracy: 0.7703\n",
            "Epoch 582/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0502 - accuracy: 0.6469 - val_loss: 0.0331 - val_accuracy: 0.7700\n",
            "Epoch 583/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0502 - accuracy: 0.6459 - val_loss: 0.0329 - val_accuracy: 0.7726\n",
            "Epoch 584/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0502 - accuracy: 0.6467 - val_loss: 0.0328 - val_accuracy: 0.7728\n",
            "Epoch 585/900\n",
            "1625/1625 [==============================] - 32s 19ms/step - loss: 0.0501 - accuracy: 0.6476 - val_loss: 0.0328 - val_accuracy: 0.7724\n",
            "Epoch 586/900\n",
            "1625/1625 [==============================] - 32s 20ms/step - loss: 0.0501 - accuracy: 0.6473 - val_loss: 0.0327 - val_accuracy: 0.7733\n",
            "Epoch 587/900\n",
            "1625/1625 [==============================] - 32s 19ms/step - loss: 0.0502 - accuracy: 0.6468 - val_loss: 0.0328 - val_accuracy: 0.7733\n",
            "Epoch 588/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0501 - accuracy: 0.6470 - val_loss: 0.0328 - val_accuracy: 0.7728\n",
            "Epoch 589/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0501 - accuracy: 0.6470 - val_loss: 0.0328 - val_accuracy: 0.7733\n",
            "Epoch 590/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0501 - accuracy: 0.6475 - val_loss: 0.0327 - val_accuracy: 0.7745\n",
            "Epoch 591/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0501 - accuracy: 0.6478 - val_loss: 0.0329 - val_accuracy: 0.7712\n",
            "Epoch 592/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0502 - accuracy: 0.6465 - val_loss: 0.0328 - val_accuracy: 0.7730\n",
            "Epoch 593/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0501 - accuracy: 0.6478 - val_loss: 0.0329 - val_accuracy: 0.7726\n",
            "Epoch 594/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0501 - accuracy: 0.6480 - val_loss: 0.0327 - val_accuracy: 0.7732\n",
            "Epoch 595/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0501 - accuracy: 0.6484 - val_loss: 0.0329 - val_accuracy: 0.7715\n",
            "Epoch 596/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0500 - accuracy: 0.6494 - val_loss: 0.0327 - val_accuracy: 0.7731\n",
            "Epoch 597/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0500 - accuracy: 0.6483 - val_loss: 0.0328 - val_accuracy: 0.7728\n",
            "Epoch 598/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0501 - accuracy: 0.6479 - val_loss: 0.0329 - val_accuracy: 0.7714\n",
            "Epoch 599/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0500 - accuracy: 0.6487 - val_loss: 0.0327 - val_accuracy: 0.7733\n",
            "Epoch 600/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0500 - accuracy: 0.6483 - val_loss: 0.0328 - val_accuracy: 0.7724\n",
            "Epoch 601/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0500 - accuracy: 0.6484 - val_loss: 0.0327 - val_accuracy: 0.7734\n",
            "Epoch 602/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0499 - accuracy: 0.6491 - val_loss: 0.0328 - val_accuracy: 0.7731\n",
            "Epoch 603/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0500 - accuracy: 0.6490 - val_loss: 0.0326 - val_accuracy: 0.7741\n",
            "Epoch 604/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0499 - accuracy: 0.6488 - val_loss: 0.0327 - val_accuracy: 0.7726\n",
            "Epoch 605/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0501 - accuracy: 0.6473 - val_loss: 0.0326 - val_accuracy: 0.7752\n",
            "Epoch 606/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0500 - accuracy: 0.6489 - val_loss: 0.0326 - val_accuracy: 0.7741\n",
            "Epoch 607/900\n",
            "1625/1625 [==============================] - 32s 20ms/step - loss: 0.0499 - accuracy: 0.6490 - val_loss: 0.0326 - val_accuracy: 0.7740\n",
            "Epoch 608/900\n",
            "1625/1625 [==============================] - 32s 20ms/step - loss: 0.0499 - accuracy: 0.6491 - val_loss: 0.0324 - val_accuracy: 0.7765\n",
            "Epoch 609/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0500 - accuracy: 0.6493 - val_loss: 0.0324 - val_accuracy: 0.7760\n",
            "Epoch 610/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0499 - accuracy: 0.6498 - val_loss: 0.0325 - val_accuracy: 0.7748\n",
            "Epoch 611/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0499 - accuracy: 0.6492 - val_loss: 0.0325 - val_accuracy: 0.7743\n",
            "Epoch 612/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0498 - accuracy: 0.6500 - val_loss: 0.0327 - val_accuracy: 0.7731\n",
            "Epoch 613/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0499 - accuracy: 0.6496 - val_loss: 0.0325 - val_accuracy: 0.7745\n",
            "Epoch 614/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0499 - accuracy: 0.6495 - val_loss: 0.0324 - val_accuracy: 0.7755\n",
            "Epoch 615/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0499 - accuracy: 0.6501 - val_loss: 0.0323 - val_accuracy: 0.7757\n",
            "Epoch 616/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0499 - accuracy: 0.6502 - val_loss: 0.0324 - val_accuracy: 0.7768\n",
            "Epoch 617/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0498 - accuracy: 0.6500 - val_loss: 0.0325 - val_accuracy: 0.7748\n",
            "Epoch 618/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0498 - accuracy: 0.6508 - val_loss: 0.0324 - val_accuracy: 0.7757\n",
            "Epoch 619/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0498 - accuracy: 0.6502 - val_loss: 0.0324 - val_accuracy: 0.7763\n",
            "Epoch 620/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0498 - accuracy: 0.6501 - val_loss: 0.0326 - val_accuracy: 0.7746\n",
            "Epoch 621/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0498 - accuracy: 0.6502 - val_loss: 0.0324 - val_accuracy: 0.7763\n",
            "Epoch 622/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0498 - accuracy: 0.6506 - val_loss: 0.0325 - val_accuracy: 0.7757\n",
            "Epoch 623/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0498 - accuracy: 0.6504 - val_loss: 0.0325 - val_accuracy: 0.7758\n",
            "Epoch 624/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0498 - accuracy: 0.6507 - val_loss: 0.0323 - val_accuracy: 0.7768\n",
            "Epoch 625/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0498 - accuracy: 0.6499 - val_loss: 0.0321 - val_accuracy: 0.7777\n",
            "Epoch 626/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0497 - accuracy: 0.6510 - val_loss: 0.0323 - val_accuracy: 0.7773\n",
            "Epoch 627/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0497 - accuracy: 0.6515 - val_loss: 0.0322 - val_accuracy: 0.7778\n",
            "Epoch 628/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0497 - accuracy: 0.6504 - val_loss: 0.0324 - val_accuracy: 0.7757\n",
            "Epoch 629/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0497 - accuracy: 0.6513 - val_loss: 0.0323 - val_accuracy: 0.7762\n",
            "Epoch 630/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0497 - accuracy: 0.6511 - val_loss: 0.0326 - val_accuracy: 0.7738\n",
            "Epoch 631/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0497 - accuracy: 0.6518 - val_loss: 0.0324 - val_accuracy: 0.7760\n",
            "Epoch 632/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0496 - accuracy: 0.6519 - val_loss: 0.0322 - val_accuracy: 0.7772\n",
            "Epoch 633/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0497 - accuracy: 0.6517 - val_loss: 0.0322 - val_accuracy: 0.7781\n",
            "Epoch 634/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0497 - accuracy: 0.6510 - val_loss: 0.0321 - val_accuracy: 0.7782\n",
            "Epoch 635/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0497 - accuracy: 0.6511 - val_loss: 0.0324 - val_accuracy: 0.7748\n",
            "Epoch 636/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0496 - accuracy: 0.6528 - val_loss: 0.0321 - val_accuracy: 0.7789\n",
            "Epoch 637/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0496 - accuracy: 0.6524 - val_loss: 0.0321 - val_accuracy: 0.7785\n",
            "Epoch 638/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0496 - accuracy: 0.6523 - val_loss: 0.0321 - val_accuracy: 0.7779\n",
            "Epoch 639/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0496 - accuracy: 0.6524 - val_loss: 0.0322 - val_accuracy: 0.7790\n",
            "Epoch 640/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0496 - accuracy: 0.6522 - val_loss: 0.0321 - val_accuracy: 0.7784\n",
            "Epoch 641/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0497 - accuracy: 0.6510 - val_loss: 0.0323 - val_accuracy: 0.7771\n",
            "Epoch 642/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0496 - accuracy: 0.6527 - val_loss: 0.0322 - val_accuracy: 0.7766\n",
            "Epoch 643/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0496 - accuracy: 0.6520 - val_loss: 0.0320 - val_accuracy: 0.7788\n",
            "Epoch 644/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0496 - accuracy: 0.6523 - val_loss: 0.0321 - val_accuracy: 0.7789\n",
            "Epoch 645/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0495 - accuracy: 0.6527 - val_loss: 0.0321 - val_accuracy: 0.7793\n",
            "Epoch 646/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0496 - accuracy: 0.6527 - val_loss: 0.0324 - val_accuracy: 0.7764\n",
            "Epoch 647/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0496 - accuracy: 0.6525 - val_loss: 0.0319 - val_accuracy: 0.7795\n",
            "Epoch 648/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0495 - accuracy: 0.6533 - val_loss: 0.0323 - val_accuracy: 0.7765\n",
            "Epoch 649/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0496 - accuracy: 0.6521 - val_loss: 0.0321 - val_accuracy: 0.7785\n",
            "Epoch 650/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0495 - accuracy: 0.6530 - val_loss: 0.0321 - val_accuracy: 0.7784\n",
            "Epoch 651/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0494 - accuracy: 0.6543 - val_loss: 0.0320 - val_accuracy: 0.7790\n",
            "Epoch 652/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0495 - accuracy: 0.6527 - val_loss: 0.0320 - val_accuracy: 0.7786\n",
            "Epoch 653/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0495 - accuracy: 0.6527 - val_loss: 0.0319 - val_accuracy: 0.7799\n",
            "Epoch 654/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0495 - accuracy: 0.6537 - val_loss: 0.0321 - val_accuracy: 0.7788\n",
            "Epoch 655/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0495 - accuracy: 0.6535 - val_loss: 0.0321 - val_accuracy: 0.7789\n",
            "Epoch 656/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0495 - accuracy: 0.6534 - val_loss: 0.0322 - val_accuracy: 0.7783\n",
            "Epoch 657/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0495 - accuracy: 0.6537 - val_loss: 0.0320 - val_accuracy: 0.7792\n",
            "Epoch 658/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0494 - accuracy: 0.6553 - val_loss: 0.0318 - val_accuracy: 0.7805\n",
            "Epoch 659/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0493 - accuracy: 0.6547 - val_loss: 0.0318 - val_accuracy: 0.7809\n",
            "Epoch 660/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0495 - accuracy: 0.6531 - val_loss: 0.0318 - val_accuracy: 0.7810\n",
            "Epoch 661/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0494 - accuracy: 0.6539 - val_loss: 0.0319 - val_accuracy: 0.7811\n",
            "Epoch 662/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0493 - accuracy: 0.6544 - val_loss: 0.0318 - val_accuracy: 0.7803\n",
            "Epoch 663/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0494 - accuracy: 0.6536 - val_loss: 0.0318 - val_accuracy: 0.7803\n",
            "Epoch 664/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0494 - accuracy: 0.6539 - val_loss: 0.0318 - val_accuracy: 0.7802\n",
            "Epoch 665/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0494 - accuracy: 0.6537 - val_loss: 0.0318 - val_accuracy: 0.7797\n",
            "Epoch 666/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0494 - accuracy: 0.6550 - val_loss: 0.0318 - val_accuracy: 0.7804\n",
            "Epoch 667/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0494 - accuracy: 0.6540 - val_loss: 0.0317 - val_accuracy: 0.7814\n",
            "Epoch 668/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0494 - accuracy: 0.6540 - val_loss: 0.0318 - val_accuracy: 0.7802\n",
            "Epoch 669/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0494 - accuracy: 0.6539 - val_loss: 0.0317 - val_accuracy: 0.7814\n",
            "Epoch 670/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0493 - accuracy: 0.6550 - val_loss: 0.0319 - val_accuracy: 0.7792\n",
            "Epoch 671/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0493 - accuracy: 0.6551 - val_loss: 0.0317 - val_accuracy: 0.7824\n",
            "Epoch 672/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0493 - accuracy: 0.6544 - val_loss: 0.0316 - val_accuracy: 0.7810\n",
            "Epoch 673/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0494 - accuracy: 0.6545 - val_loss: 0.0316 - val_accuracy: 0.7824\n",
            "Epoch 674/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0493 - accuracy: 0.6547 - val_loss: 0.0318 - val_accuracy: 0.7807\n",
            "Epoch 675/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0492 - accuracy: 0.6554 - val_loss: 0.0318 - val_accuracy: 0.7809\n",
            "Epoch 676/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0492 - accuracy: 0.6552 - val_loss: 0.0316 - val_accuracy: 0.7822\n",
            "Epoch 677/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0493 - accuracy: 0.6544 - val_loss: 0.0319 - val_accuracy: 0.7787\n",
            "Epoch 678/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0493 - accuracy: 0.6552 - val_loss: 0.0318 - val_accuracy: 0.7802\n",
            "Epoch 679/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0493 - accuracy: 0.6550 - val_loss: 0.0316 - val_accuracy: 0.7827\n",
            "Epoch 680/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0493 - accuracy: 0.6549 - val_loss: 0.0316 - val_accuracy: 0.7816\n",
            "Epoch 681/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0492 - accuracy: 0.6556 - val_loss: 0.0315 - val_accuracy: 0.7831\n",
            "Epoch 682/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0492 - accuracy: 0.6561 - val_loss: 0.0315 - val_accuracy: 0.7831\n",
            "Epoch 683/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0492 - accuracy: 0.6557 - val_loss: 0.0318 - val_accuracy: 0.7797\n",
            "Epoch 684/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0492 - accuracy: 0.6561 - val_loss: 0.0315 - val_accuracy: 0.7830\n",
            "Epoch 685/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0491 - accuracy: 0.6562 - val_loss: 0.0315 - val_accuracy: 0.7826\n",
            "Epoch 686/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0492 - accuracy: 0.6557 - val_loss: 0.0315 - val_accuracy: 0.7833\n",
            "Epoch 687/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0492 - accuracy: 0.6549 - val_loss: 0.0316 - val_accuracy: 0.7818\n",
            "Epoch 688/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0492 - accuracy: 0.6565 - val_loss: 0.0314 - val_accuracy: 0.7833\n",
            "Epoch 689/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0492 - accuracy: 0.6560 - val_loss: 0.0316 - val_accuracy: 0.7805\n",
            "Epoch 690/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0491 - accuracy: 0.6565 - val_loss: 0.0316 - val_accuracy: 0.7815\n",
            "Epoch 691/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0491 - accuracy: 0.6561 - val_loss: 0.0315 - val_accuracy: 0.7820\n",
            "Epoch 692/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0492 - accuracy: 0.6557 - val_loss: 0.0319 - val_accuracy: 0.7801\n",
            "Epoch 693/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0491 - accuracy: 0.6562 - val_loss: 0.0317 - val_accuracy: 0.7814\n",
            "Epoch 694/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0491 - accuracy: 0.6564 - val_loss: 0.0316 - val_accuracy: 0.7832\n",
            "Epoch 695/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0490 - accuracy: 0.6576 - val_loss: 0.0315 - val_accuracy: 0.7824\n",
            "Epoch 696/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0491 - accuracy: 0.6573 - val_loss: 0.0316 - val_accuracy: 0.7813\n",
            "Epoch 697/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0490 - accuracy: 0.6573 - val_loss: 0.0314 - val_accuracy: 0.7844\n",
            "Epoch 698/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0491 - accuracy: 0.6564 - val_loss: 0.0315 - val_accuracy: 0.7836\n",
            "Epoch 699/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0491 - accuracy: 0.6567 - val_loss: 0.0315 - val_accuracy: 0.7830\n",
            "Epoch 700/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0490 - accuracy: 0.6577 - val_loss: 0.0314 - val_accuracy: 0.7829\n",
            "Epoch 701/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0491 - accuracy: 0.6563 - val_loss: 0.0313 - val_accuracy: 0.7843\n",
            "Epoch 702/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0490 - accuracy: 0.6574 - val_loss: 0.0313 - val_accuracy: 0.7839\n",
            "Epoch 703/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0490 - accuracy: 0.6569 - val_loss: 0.0313 - val_accuracy: 0.7836\n",
            "Epoch 704/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0490 - accuracy: 0.6573 - val_loss: 0.0314 - val_accuracy: 0.7822\n",
            "Epoch 705/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0490 - accuracy: 0.6575 - val_loss: 0.0314 - val_accuracy: 0.7838\n",
            "Epoch 706/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0490 - accuracy: 0.6577 - val_loss: 0.0314 - val_accuracy: 0.7841\n",
            "Epoch 707/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0490 - accuracy: 0.6580 - val_loss: 0.0314 - val_accuracy: 0.7827\n",
            "Epoch 708/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0491 - accuracy: 0.6566 - val_loss: 0.0314 - val_accuracy: 0.7834\n",
            "Epoch 709/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0489 - accuracy: 0.6583 - val_loss: 0.0312 - val_accuracy: 0.7850\n",
            "Epoch 710/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0490 - accuracy: 0.6572 - val_loss: 0.0313 - val_accuracy: 0.7840\n",
            "Epoch 711/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0490 - accuracy: 0.6578 - val_loss: 0.0313 - val_accuracy: 0.7839\n",
            "Epoch 712/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0490 - accuracy: 0.6575 - val_loss: 0.0311 - val_accuracy: 0.7856\n",
            "Epoch 713/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0489 - accuracy: 0.6577 - val_loss: 0.0312 - val_accuracy: 0.7848\n",
            "Epoch 714/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0489 - accuracy: 0.6586 - val_loss: 0.0312 - val_accuracy: 0.7845\n",
            "Epoch 715/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0488 - accuracy: 0.6595 - val_loss: 0.0312 - val_accuracy: 0.7847\n",
            "Epoch 716/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0489 - accuracy: 0.6583 - val_loss: 0.0310 - val_accuracy: 0.7869\n",
            "Epoch 717/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0489 - accuracy: 0.6591 - val_loss: 0.0310 - val_accuracy: 0.7863\n",
            "Epoch 718/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0489 - accuracy: 0.6584 - val_loss: 0.0313 - val_accuracy: 0.7855\n",
            "Epoch 719/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0489 - accuracy: 0.6586 - val_loss: 0.0315 - val_accuracy: 0.7824\n",
            "Epoch 720/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0489 - accuracy: 0.6583 - val_loss: 0.0314 - val_accuracy: 0.7827\n",
            "Epoch 721/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0489 - accuracy: 0.6580 - val_loss: 0.0310 - val_accuracy: 0.7868\n",
            "Epoch 722/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0489 - accuracy: 0.6584 - val_loss: 0.0312 - val_accuracy: 0.7853\n",
            "Epoch 723/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0488 - accuracy: 0.6596 - val_loss: 0.0311 - val_accuracy: 0.7850\n",
            "Epoch 724/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0488 - accuracy: 0.6590 - val_loss: 0.0310 - val_accuracy: 0.7869\n",
            "Epoch 725/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0489 - accuracy: 0.6592 - val_loss: 0.0313 - val_accuracy: 0.7850\n",
            "Epoch 726/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0488 - accuracy: 0.6597 - val_loss: 0.0311 - val_accuracy: 0.7859\n",
            "Epoch 727/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0489 - accuracy: 0.6589 - val_loss: 0.0312 - val_accuracy: 0.7843\n",
            "Epoch 728/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0488 - accuracy: 0.6596 - val_loss: 0.0310 - val_accuracy: 0.7864\n",
            "Epoch 729/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0488 - accuracy: 0.6594 - val_loss: 0.0314 - val_accuracy: 0.7838\n",
            "Epoch 730/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0488 - accuracy: 0.6591 - val_loss: 0.0309 - val_accuracy: 0.7875\n",
            "Epoch 731/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0488 - accuracy: 0.6589 - val_loss: 0.0312 - val_accuracy: 0.7842\n",
            "Epoch 732/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0488 - accuracy: 0.6589 - val_loss: 0.0311 - val_accuracy: 0.7861\n",
            "Epoch 733/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0488 - accuracy: 0.6598 - val_loss: 0.0311 - val_accuracy: 0.7855\n",
            "Epoch 734/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0487 - accuracy: 0.6604 - val_loss: 0.0310 - val_accuracy: 0.7879\n",
            "Epoch 735/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0488 - accuracy: 0.6592 - val_loss: 0.0309 - val_accuracy: 0.7880\n",
            "Epoch 736/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0488 - accuracy: 0.6600 - val_loss: 0.0309 - val_accuracy: 0.7875\n",
            "Epoch 737/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0487 - accuracy: 0.6604 - val_loss: 0.0312 - val_accuracy: 0.7850\n",
            "Epoch 738/900\n",
            "1625/1625 [==============================] - 31s 19ms/step - loss: 0.0488 - accuracy: 0.6600 - val_loss: 0.0308 - val_accuracy: 0.7884\n",
            "Epoch 739/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0488 - accuracy: 0.6593 - val_loss: 0.0308 - val_accuracy: 0.7889\n",
            "Epoch 740/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0486 - accuracy: 0.6613 - val_loss: 0.0307 - val_accuracy: 0.7889\n",
            "Epoch 741/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0487 - accuracy: 0.6597 - val_loss: 0.0310 - val_accuracy: 0.7856\n",
            "Epoch 742/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0487 - accuracy: 0.6608 - val_loss: 0.0309 - val_accuracy: 0.7883\n",
            "Epoch 743/900\n",
            "1625/1625 [==============================] - 30s 19ms/step - loss: 0.0487 - accuracy: 0.6601 - val_loss: 0.0309 - val_accuracy: 0.7876\n",
            "Epoch 744/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0487 - accuracy: 0.6602 - val_loss: 0.0310 - val_accuracy: 0.7869\n",
            "Epoch 745/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0487 - accuracy: 0.6605 - val_loss: 0.0309 - val_accuracy: 0.7887\n",
            "Epoch 746/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0487 - accuracy: 0.6604 - val_loss: 0.0309 - val_accuracy: 0.7872\n",
            "Epoch 747/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0486 - accuracy: 0.6616 - val_loss: 0.0310 - val_accuracy: 0.7871\n",
            "Epoch 748/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0486 - accuracy: 0.6616 - val_loss: 0.0308 - val_accuracy: 0.7879\n",
            "Epoch 749/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0487 - accuracy: 0.6603 - val_loss: 0.0308 - val_accuracy: 0.7882\n",
            "Epoch 750/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0485 - accuracy: 0.6618 - val_loss: 0.0307 - val_accuracy: 0.7892\n",
            "Epoch 751/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0486 - accuracy: 0.6614 - val_loss: 0.0308 - val_accuracy: 0.7891\n",
            "Epoch 752/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0486 - accuracy: 0.6607 - val_loss: 0.0307 - val_accuracy: 0.7891\n",
            "Epoch 753/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0486 - accuracy: 0.6615 - val_loss: 0.0308 - val_accuracy: 0.7890\n",
            "Epoch 754/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0486 - accuracy: 0.6617 - val_loss: 0.0306 - val_accuracy: 0.7894\n",
            "Epoch 755/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0487 - accuracy: 0.6608 - val_loss: 0.0308 - val_accuracy: 0.7879\n",
            "Epoch 756/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0486 - accuracy: 0.6609 - val_loss: 0.0308 - val_accuracy: 0.7883\n",
            "Epoch 757/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0487 - accuracy: 0.6606 - val_loss: 0.0306 - val_accuracy: 0.7898\n",
            "Epoch 758/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0485 - accuracy: 0.6624 - val_loss: 0.0306 - val_accuracy: 0.7900\n",
            "Epoch 759/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0485 - accuracy: 0.6615 - val_loss: 0.0310 - val_accuracy: 0.7866\n",
            "Epoch 760/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0485 - accuracy: 0.6625 - val_loss: 0.0307 - val_accuracy: 0.7891\n",
            "Epoch 761/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0485 - accuracy: 0.6627 - val_loss: 0.0306 - val_accuracy: 0.7891\n",
            "Epoch 762/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0485 - accuracy: 0.6624 - val_loss: 0.0308 - val_accuracy: 0.7885\n",
            "Epoch 763/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0486 - accuracy: 0.6611 - val_loss: 0.0309 - val_accuracy: 0.7888\n",
            "Epoch 764/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0485 - accuracy: 0.6620 - val_loss: 0.0307 - val_accuracy: 0.7888\n",
            "Epoch 765/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0485 - accuracy: 0.6628 - val_loss: 0.0308 - val_accuracy: 0.7876\n",
            "Epoch 766/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0485 - accuracy: 0.6625 - val_loss: 0.0307 - val_accuracy: 0.7886\n",
            "Epoch 767/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0485 - accuracy: 0.6617 - val_loss: 0.0306 - val_accuracy: 0.7897\n",
            "Epoch 768/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0486 - accuracy: 0.6614 - val_loss: 0.0306 - val_accuracy: 0.7892\n",
            "Epoch 769/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0485 - accuracy: 0.6626 - val_loss: 0.0306 - val_accuracy: 0.7895\n",
            "Epoch 770/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0485 - accuracy: 0.6618 - val_loss: 0.0306 - val_accuracy: 0.7904\n",
            "Epoch 771/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0484 - accuracy: 0.6627 - val_loss: 0.0306 - val_accuracy: 0.7901\n",
            "Epoch 772/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0485 - accuracy: 0.6623 - val_loss: 0.0308 - val_accuracy: 0.7877\n",
            "Epoch 773/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0484 - accuracy: 0.6626 - val_loss: 0.0305 - val_accuracy: 0.7901\n",
            "Epoch 774/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0484 - accuracy: 0.6626 - val_loss: 0.0305 - val_accuracy: 0.7912\n",
            "Epoch 775/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0483 - accuracy: 0.6631 - val_loss: 0.0306 - val_accuracy: 0.7908\n",
            "Epoch 776/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0484 - accuracy: 0.6631 - val_loss: 0.0305 - val_accuracy: 0.7898\n",
            "Epoch 777/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0484 - accuracy: 0.6630 - val_loss: 0.0307 - val_accuracy: 0.7889\n",
            "Epoch 778/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0484 - accuracy: 0.6634 - val_loss: 0.0304 - val_accuracy: 0.7913\n",
            "Epoch 779/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0484 - accuracy: 0.6630 - val_loss: 0.0305 - val_accuracy: 0.7906\n",
            "Epoch 780/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0483 - accuracy: 0.6641 - val_loss: 0.0304 - val_accuracy: 0.7917\n",
            "Epoch 781/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0483 - accuracy: 0.6641 - val_loss: 0.0303 - val_accuracy: 0.7924\n",
            "Epoch 782/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0484 - accuracy: 0.6632 - val_loss: 0.0307 - val_accuracy: 0.7899\n",
            "Epoch 783/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0484 - accuracy: 0.6640 - val_loss: 0.0306 - val_accuracy: 0.7906\n",
            "Epoch 784/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0484 - accuracy: 0.6630 - val_loss: 0.0306 - val_accuracy: 0.7901\n",
            "Epoch 785/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0484 - accuracy: 0.6639 - val_loss: 0.0305 - val_accuracy: 0.7897\n",
            "Epoch 786/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0483 - accuracy: 0.6639 - val_loss: 0.0305 - val_accuracy: 0.7898\n",
            "Epoch 787/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0485 - accuracy: 0.6629 - val_loss: 0.0308 - val_accuracy: 0.7892\n",
            "Epoch 788/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0482 - accuracy: 0.6646 - val_loss: 0.0305 - val_accuracy: 0.7901\n",
            "Epoch 789/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0483 - accuracy: 0.6636 - val_loss: 0.0304 - val_accuracy: 0.7906\n",
            "Epoch 790/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0483 - accuracy: 0.6639 - val_loss: 0.0305 - val_accuracy: 0.7906\n",
            "Epoch 791/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0483 - accuracy: 0.6643 - val_loss: 0.0303 - val_accuracy: 0.7919\n",
            "Epoch 792/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0483 - accuracy: 0.6641 - val_loss: 0.0304 - val_accuracy: 0.7907\n",
            "Epoch 793/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0484 - accuracy: 0.6629 - val_loss: 0.0305 - val_accuracy: 0.7912\n",
            "Epoch 794/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0482 - accuracy: 0.6648 - val_loss: 0.0304 - val_accuracy: 0.7914\n",
            "Epoch 795/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0483 - accuracy: 0.6637 - val_loss: 0.0306 - val_accuracy: 0.7893\n",
            "Epoch 796/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0483 - accuracy: 0.6646 - val_loss: 0.0303 - val_accuracy: 0.7924\n",
            "Epoch 797/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0483 - accuracy: 0.6638 - val_loss: 0.0304 - val_accuracy: 0.7917\n",
            "Epoch 798/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0483 - accuracy: 0.6644 - val_loss: 0.0303 - val_accuracy: 0.7914\n",
            "Epoch 799/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0482 - accuracy: 0.6648 - val_loss: 0.0302 - val_accuracy: 0.7927\n",
            "Epoch 800/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0482 - accuracy: 0.6656 - val_loss: 0.0302 - val_accuracy: 0.7925\n",
            "Epoch 801/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0482 - accuracy: 0.6645 - val_loss: 0.0303 - val_accuracy: 0.7919\n",
            "Epoch 802/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0482 - accuracy: 0.6651 - val_loss: 0.0303 - val_accuracy: 0.7919\n",
            "Epoch 803/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0481 - accuracy: 0.6658 - val_loss: 0.0305 - val_accuracy: 0.7912\n",
            "Epoch 804/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0482 - accuracy: 0.6647 - val_loss: 0.0301 - val_accuracy: 0.7924\n",
            "Epoch 805/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0483 - accuracy: 0.6644 - val_loss: 0.0304 - val_accuracy: 0.7905\n",
            "Epoch 806/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0481 - accuracy: 0.6655 - val_loss: 0.0303 - val_accuracy: 0.7921\n",
            "Epoch 807/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0482 - accuracy: 0.6649 - val_loss: 0.0302 - val_accuracy: 0.7931\n",
            "Epoch 808/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0481 - accuracy: 0.6663 - val_loss: 0.0302 - val_accuracy: 0.7918\n",
            "Epoch 809/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0481 - accuracy: 0.6663 - val_loss: 0.0304 - val_accuracy: 0.7903\n",
            "Epoch 810/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0481 - accuracy: 0.6658 - val_loss: 0.0300 - val_accuracy: 0.7940\n",
            "Epoch 811/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0481 - accuracy: 0.6657 - val_loss: 0.0301 - val_accuracy: 0.7931\n",
            "Epoch 812/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0482 - accuracy: 0.6648 - val_loss: 0.0304 - val_accuracy: 0.7906\n",
            "Epoch 813/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0481 - accuracy: 0.6658 - val_loss: 0.0301 - val_accuracy: 0.7945\n",
            "Epoch 814/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0481 - accuracy: 0.6658 - val_loss: 0.0301 - val_accuracy: 0.7936\n",
            "Epoch 815/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0481 - accuracy: 0.6658 - val_loss: 0.0302 - val_accuracy: 0.7924\n",
            "Epoch 816/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0481 - accuracy: 0.6656 - val_loss: 0.0301 - val_accuracy: 0.7933\n",
            "Epoch 817/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0481 - accuracy: 0.6658 - val_loss: 0.0301 - val_accuracy: 0.7927\n",
            "Epoch 818/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0480 - accuracy: 0.6662 - val_loss: 0.0300 - val_accuracy: 0.7942\n",
            "Epoch 819/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0481 - accuracy: 0.6660 - val_loss: 0.0301 - val_accuracy: 0.7936\n",
            "Epoch 820/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0481 - accuracy: 0.6663 - val_loss: 0.0303 - val_accuracy: 0.7923\n",
            "Epoch 821/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0481 - accuracy: 0.6655 - val_loss: 0.0302 - val_accuracy: 0.7926\n",
            "Epoch 822/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0480 - accuracy: 0.6664 - val_loss: 0.0300 - val_accuracy: 0.7946\n",
            "Epoch 823/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0480 - accuracy: 0.6661 - val_loss: 0.0300 - val_accuracy: 0.7947\n",
            "Epoch 824/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0480 - accuracy: 0.6665 - val_loss: 0.0300 - val_accuracy: 0.7930\n",
            "Epoch 825/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0481 - accuracy: 0.6656 - val_loss: 0.0300 - val_accuracy: 0.7930\n",
            "Epoch 826/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0480 - accuracy: 0.6664 - val_loss: 0.0301 - val_accuracy: 0.7954\n",
            "Epoch 827/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0480 - accuracy: 0.6667 - val_loss: 0.0302 - val_accuracy: 0.7934\n",
            "Epoch 828/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0479 - accuracy: 0.6679 - val_loss: 0.0301 - val_accuracy: 0.7925\n",
            "Epoch 829/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0480 - accuracy: 0.6660 - val_loss: 0.0299 - val_accuracy: 0.7943\n",
            "Epoch 830/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0480 - accuracy: 0.6662 - val_loss: 0.0301 - val_accuracy: 0.7943\n",
            "Epoch 831/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0479 - accuracy: 0.6663 - val_loss: 0.0302 - val_accuracy: 0.7928\n",
            "Epoch 832/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0480 - accuracy: 0.6672 - val_loss: 0.0302 - val_accuracy: 0.7918\n",
            "Epoch 833/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0479 - accuracy: 0.6671 - val_loss: 0.0301 - val_accuracy: 0.7933\n",
            "Epoch 834/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0480 - accuracy: 0.6667 - val_loss: 0.0302 - val_accuracy: 0.7932\n",
            "Epoch 835/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0480 - accuracy: 0.6659 - val_loss: 0.0300 - val_accuracy: 0.7946\n",
            "Epoch 836/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0479 - accuracy: 0.6680 - val_loss: 0.0301 - val_accuracy: 0.7939\n",
            "Epoch 837/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0479 - accuracy: 0.6669 - val_loss: 0.0300 - val_accuracy: 0.7943\n",
            "Epoch 838/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0478 - accuracy: 0.6673 - val_loss: 0.0299 - val_accuracy: 0.7955\n",
            "Epoch 839/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0480 - accuracy: 0.6664 - val_loss: 0.0300 - val_accuracy: 0.7929\n",
            "Epoch 840/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0479 - accuracy: 0.6679 - val_loss: 0.0300 - val_accuracy: 0.7932\n",
            "Epoch 841/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0479 - accuracy: 0.6673 - val_loss: 0.0301 - val_accuracy: 0.7931\n",
            "Epoch 842/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0479 - accuracy: 0.6679 - val_loss: 0.0299 - val_accuracy: 0.7956\n",
            "Epoch 843/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0479 - accuracy: 0.6674 - val_loss: 0.0298 - val_accuracy: 0.7946\n",
            "Epoch 844/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0479 - accuracy: 0.6682 - val_loss: 0.0298 - val_accuracy: 0.7961\n",
            "Epoch 845/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0479 - accuracy: 0.6678 - val_loss: 0.0299 - val_accuracy: 0.7950\n",
            "Epoch 846/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0479 - accuracy: 0.6675 - val_loss: 0.0302 - val_accuracy: 0.7921\n",
            "Epoch 847/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0478 - accuracy: 0.6683 - val_loss: 0.0304 - val_accuracy: 0.7898\n",
            "Epoch 848/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0479 - accuracy: 0.6675 - val_loss: 0.0299 - val_accuracy: 0.7946\n",
            "Epoch 849/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0478 - accuracy: 0.6682 - val_loss: 0.0299 - val_accuracy: 0.7949\n",
            "Epoch 850/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0477 - accuracy: 0.6693 - val_loss: 0.0299 - val_accuracy: 0.7958\n",
            "Epoch 851/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0478 - accuracy: 0.6682 - val_loss: 0.0298 - val_accuracy: 0.7959\n",
            "Epoch 852/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0478 - accuracy: 0.6682 - val_loss: 0.0298 - val_accuracy: 0.7954\n",
            "Epoch 853/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0478 - accuracy: 0.6685 - val_loss: 0.0297 - val_accuracy: 0.7963\n",
            "Epoch 854/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0477 - accuracy: 0.6699 - val_loss: 0.0298 - val_accuracy: 0.7957\n",
            "Epoch 855/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0477 - accuracy: 0.6699 - val_loss: 0.0299 - val_accuracy: 0.7948\n",
            "Epoch 856/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0478 - accuracy: 0.6685 - val_loss: 0.0298 - val_accuracy: 0.7953\n",
            "Epoch 857/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0478 - accuracy: 0.6691 - val_loss: 0.0300 - val_accuracy: 0.7943\n",
            "Epoch 858/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0478 - accuracy: 0.6684 - val_loss: 0.0298 - val_accuracy: 0.7962\n",
            "Epoch 859/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0477 - accuracy: 0.6694 - val_loss: 0.0298 - val_accuracy: 0.7954\n",
            "Epoch 860/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0479 - accuracy: 0.6676 - val_loss: 0.0297 - val_accuracy: 0.7968\n",
            "Epoch 861/900\n",
            "1625/1625 [==============================] - 30s 18ms/step - loss: 0.0477 - accuracy: 0.6696 - val_loss: 0.0297 - val_accuracy: 0.7961\n",
            "Epoch 862/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0477 - accuracy: 0.6697 - val_loss: 0.0297 - val_accuracy: 0.7961\n",
            "Epoch 863/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0477 - accuracy: 0.6689 - val_loss: 0.0298 - val_accuracy: 0.7954\n",
            "Epoch 864/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0477 - accuracy: 0.6695 - val_loss: 0.0296 - val_accuracy: 0.7965\n",
            "Epoch 865/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0478 - accuracy: 0.6694 - val_loss: 0.0297 - val_accuracy: 0.7966\n",
            "Epoch 866/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0477 - accuracy: 0.6696 - val_loss: 0.0297 - val_accuracy: 0.7964\n",
            "Epoch 867/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0477 - accuracy: 0.6689 - val_loss: 0.0296 - val_accuracy: 0.7971\n",
            "Epoch 868/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0478 - accuracy: 0.6690 - val_loss: 0.0295 - val_accuracy: 0.7984\n",
            "Epoch 869/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0477 - accuracy: 0.6691 - val_loss: 0.0295 - val_accuracy: 0.7983\n",
            "Epoch 870/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0477 - accuracy: 0.6693 - val_loss: 0.0295 - val_accuracy: 0.7983\n",
            "Epoch 871/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0476 - accuracy: 0.6699 - val_loss: 0.0297 - val_accuracy: 0.7964\n",
            "Epoch 872/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0476 - accuracy: 0.6694 - val_loss: 0.0295 - val_accuracy: 0.7980\n",
            "Epoch 873/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0477 - accuracy: 0.6695 - val_loss: 0.0296 - val_accuracy: 0.7980\n",
            "Epoch 874/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0477 - accuracy: 0.6697 - val_loss: 0.0296 - val_accuracy: 0.7965\n",
            "Epoch 875/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0476 - accuracy: 0.6703 - val_loss: 0.0294 - val_accuracy: 0.7985\n",
            "Epoch 876/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0477 - accuracy: 0.6698 - val_loss: 0.0296 - val_accuracy: 0.7970\n",
            "Epoch 877/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0476 - accuracy: 0.6704 - val_loss: 0.0296 - val_accuracy: 0.7965\n",
            "Epoch 878/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0476 - accuracy: 0.6709 - val_loss: 0.0295 - val_accuracy: 0.7977\n",
            "Epoch 879/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0476 - accuracy: 0.6703 - val_loss: 0.0295 - val_accuracy: 0.7979\n",
            "Epoch 880/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0477 - accuracy: 0.6697 - val_loss: 0.0297 - val_accuracy: 0.7958\n",
            "Epoch 881/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0477 - accuracy: 0.6687 - val_loss: 0.0297 - val_accuracy: 0.7954\n",
            "Epoch 882/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0476 - accuracy: 0.6694 - val_loss: 0.0297 - val_accuracy: 0.7964\n",
            "Epoch 883/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0476 - accuracy: 0.6705 - val_loss: 0.0294 - val_accuracy: 0.7993\n",
            "Epoch 884/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0476 - accuracy: 0.6698 - val_loss: 0.0295 - val_accuracy: 0.7968\n",
            "Epoch 885/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0475 - accuracy: 0.6717 - val_loss: 0.0295 - val_accuracy: 0.7973\n",
            "Epoch 886/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0475 - accuracy: 0.6716 - val_loss: 0.0295 - val_accuracy: 0.7982\n",
            "Epoch 887/900\n",
            "1625/1625 [==============================] - 28s 17ms/step - loss: 0.0476 - accuracy: 0.6703 - val_loss: 0.0294 - val_accuracy: 0.7984\n",
            "Epoch 888/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0475 - accuracy: 0.6708 - val_loss: 0.0294 - val_accuracy: 0.7988\n",
            "Epoch 889/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0476 - accuracy: 0.6704 - val_loss: 0.0293 - val_accuracy: 0.8001\n",
            "Epoch 890/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0474 - accuracy: 0.6710 - val_loss: 0.0294 - val_accuracy: 0.7988\n",
            "Epoch 891/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0475 - accuracy: 0.6707 - val_loss: 0.0297 - val_accuracy: 0.7971\n",
            "Epoch 892/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0474 - accuracy: 0.6719 - val_loss: 0.0294 - val_accuracy: 0.7993\n",
            "Epoch 893/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0476 - accuracy: 0.6708 - val_loss: 0.0294 - val_accuracy: 0.7988\n",
            "Epoch 894/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0475 - accuracy: 0.6708 - val_loss: 0.0293 - val_accuracy: 0.7998\n",
            "Epoch 895/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0476 - accuracy: 0.6699 - val_loss: 0.0294 - val_accuracy: 0.7990\n",
            "Epoch 896/900\n",
            "1625/1625 [==============================] - 28s 18ms/step - loss: 0.0475 - accuracy: 0.6721 - val_loss: 0.0294 - val_accuracy: 0.7985\n",
            "Epoch 897/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0474 - accuracy: 0.6721 - val_loss: 0.0295 - val_accuracy: 0.7977\n",
            "Epoch 898/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0476 - accuracy: 0.6707 - val_loss: 0.0294 - val_accuracy: 0.7982\n",
            "Epoch 899/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0475 - accuracy: 0.6717 - val_loss: 0.0292 - val_accuracy: 0.8009\n",
            "Epoch 900/900\n",
            "1625/1625 [==============================] - 29s 18ms/step - loss: 0.0475 - accuracy: 0.6720 - val_loss: 0.0294 - val_accuracy: 0.7981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBVj0zXPl5AR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "733fffbd-b85f-4d9a-f19b-27aa3c917593"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "epochs=range(1,len(acc)+1)\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(epochs,acc,'bo',label='Training acc')\n",
        "plt.plot(epochs,val_acc,'b',label='Validation acc')\n",
        "plt.title(\"training and validation accuracy\")\n",
        "plt.legend()\n",
        "plt.savefig(\"/content/drive/My Drive/deap_egg_final/accuracy_resilt.png\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0dFpja51zNh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "95828e36-69fc-448e-e1b3-a4f70d239091"
      },
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "\n",
        "plt.plot(epochs,loss,'bo',label='Training loss')\n",
        "plt.plot(epochs,val_loss,'b',label='Validation loss')\n",
        "plt.title(\"training and validation loss\")\n",
        "plt.legend()\n",
        "plt.savefig(\"/content/drive/My Drive/deap_egg_final/loss.jpg\")\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu4gZa0u3apn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/drive/My Drive/deap_egg_final/egg_0_valance.h5\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqMhgX3D56mm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "47f1ec90-c100-4ce9-912c-6d139bc5de6d"
      },
      "source": [
        "model.save(\"/content/drive/My Drive/deap_egg_final/egg_0_valance\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/deap_egg_final/egg_0_valance/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laElwef1596U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "()"
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}